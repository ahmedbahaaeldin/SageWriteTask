{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d5d167e",
   "metadata": {},
   "source": [
    "# SageWrite Notebook\n",
    "The following notebook is divided into the following sections:\n",
    "<ol>\n",
    "    <li> Data Exploration </li>\n",
    "    <li> Text Classification </li>\n",
    "    <li> Text Generation </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "2f7db7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot\n",
    "import Levenshtein\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686e155f",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "In this segment, we are going to explore the text length distrubtion of the 100 articles we have. Moreover, we are trying to find different insights in the text that might serve the final purpose (write better articles). \n",
    "\n",
    "One of the insights was to check the correlation between the length of the outline draft and the original text. This might seem counter intuitive in the beginning, however, we believe that there is a hidden golden ratio between a draft and final text. Then by applying this to larger dataset (because numbers here can be tricky due to data size) we can find great insights about the ratio we need to filter against to maintain high quality data to train our model on for enhancing our final article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "828738e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('SageWrite_corpus_0.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9453d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sb_summary_id</th>\n",
       "      <th>original_text_id</th>\n",
       "      <th>colloquial_language</th>\n",
       "      <th>formal_language</th>\n",
       "      <th>unnecessary_jargon</th>\n",
       "      <th>verbosity</th>\n",
       "      <th>opaque_writing</th>\n",
       "      <th>overly_long_sentences</th>\n",
       "      <th>excessively_complex_syntax</th>\n",
       "      <th>abuse_of_passive_sentences</th>\n",
       "      <th>...</th>\n",
       "      <th>pretentiousness</th>\n",
       "      <th>engaging_writing</th>\n",
       "      <th>dull_writing</th>\n",
       "      <th>unclear</th>\n",
       "      <th>word_choice</th>\n",
       "      <th>repetition</th>\n",
       "      <th>fragment</th>\n",
       "      <th>non_sequitor</th>\n",
       "      <th>poor_flow</th>\n",
       "      <th>redundant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50.500000</td>\n",
       "      <td>124.850000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.011492</td>\n",
       "      <td>42.632651</td>\n",
       "      <td>0.140705</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.338744</td>\n",
       "      <td>0.140705</td>\n",
       "      <td>0.502921</td>\n",
       "      <td>0.277798</td>\n",
       "      <td>0.293189</td>\n",
       "      <td>0.171447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171447</td>\n",
       "      <td>0.337998</td>\n",
       "      <td>0.402517</td>\n",
       "      <td>0.995901</td>\n",
       "      <td>0.870388</td>\n",
       "      <td>0.242878</td>\n",
       "      <td>0.435194</td>\n",
       "      <td>0.404395</td>\n",
       "      <td>0.426875</td>\n",
       "      <td>0.307482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.750000</td>\n",
       "      <td>97.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.500000</td>\n",
       "      <td>122.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>75.250000</td>\n",
       "      <td>168.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sb_summary_id  original_text_id  colloquial_language  formal_language  \\\n",
       "count     100.000000        100.000000           100.000000           100.00   \n",
       "mean       50.500000        124.850000             0.020000             0.01   \n",
       "std        29.011492         42.632651             0.140705             0.10   \n",
       "min         1.000000         52.000000             0.000000             0.00   \n",
       "25%        25.750000         97.750000             0.000000             0.00   \n",
       "50%        50.500000        122.500000             0.000000             0.00   \n",
       "75%        75.250000        168.250000             0.000000             0.00   \n",
       "max       100.000000        195.000000             1.000000             1.00   \n",
       "\n",
       "       unnecessary_jargon   verbosity  opaque_writing  overly_long_sentences  \\\n",
       "count          100.000000  100.000000      100.000000             100.000000   \n",
       "mean             0.080000    0.020000        0.360000               0.060000   \n",
       "std              0.338744    0.140705        0.502921               0.277798   \n",
       "min              0.000000    0.000000        0.000000               0.000000   \n",
       "25%              0.000000    0.000000        0.000000               0.000000   \n",
       "50%              0.000000    0.000000        0.000000               0.000000   \n",
       "75%              0.000000    0.000000        1.000000               0.000000   \n",
       "max              2.000000    1.000000        2.000000               2.000000   \n",
       "\n",
       "       excessively_complex_syntax  abuse_of_passive_sentences  ...  \\\n",
       "count                  100.000000                  100.000000  ...   \n",
       "mean                     0.070000                    0.030000  ...   \n",
       "std                      0.293189                    0.171447  ...   \n",
       "min                      0.000000                    0.000000  ...   \n",
       "25%                      0.000000                    0.000000  ...   \n",
       "50%                      0.000000                    0.000000  ...   \n",
       "75%                      0.000000                    0.000000  ...   \n",
       "max                      2.000000                    1.000000  ...   \n",
       "\n",
       "       pretentiousness  engaging_writing  dull_writing     unclear  \\\n",
       "count       100.000000        100.000000    100.000000  100.000000   \n",
       "mean          0.030000          0.130000      0.140000    0.590000   \n",
       "std           0.171447          0.337998      0.402517    0.995901   \n",
       "min           0.000000          0.000000      0.000000    0.000000   \n",
       "25%           0.000000          0.000000      0.000000    0.000000   \n",
       "50%           0.000000          0.000000      0.000000    0.000000   \n",
       "75%           0.000000          0.000000      0.000000    1.000000   \n",
       "max           1.000000          1.000000      2.000000    3.000000   \n",
       "\n",
       "       word_choice  repetition    fragment  non_sequitor   poor_flow  \\\n",
       "count   100.000000  100.000000  100.000000    100.000000  100.000000   \n",
       "mean      0.500000    0.040000    0.150000      0.090000    0.140000   \n",
       "std       0.870388    0.242878    0.435194      0.404395    0.426875   \n",
       "min       0.000000    0.000000    0.000000      0.000000    0.000000   \n",
       "25%       0.000000    0.000000    0.000000      0.000000    0.000000   \n",
       "50%       0.000000    0.000000    0.000000      0.000000    0.000000   \n",
       "75%       1.000000    0.000000    0.000000      0.000000    0.000000   \n",
       "max       3.000000    2.000000    2.000000      3.000000    2.000000   \n",
       "\n",
       "        redundant  \n",
       "count  100.000000  \n",
       "mean     0.080000  \n",
       "std      0.307482  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      0.000000  \n",
       "75%      0.000000  \n",
       "max      2.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d7eb451",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "def length_distrubtion(text : list) -> list:\n",
    "    text_length = []\n",
    "    \n",
    "    for t in text:\n",
    "        t = re.sub('\\n','',t)\n",
    "        tokens = t.split(' ')\n",
    "        text_length.append(len(tokens))\n",
    "        \n",
    "    sns.barplot(x=[i for i in range(100)],y=text_length);\n",
    "    return text_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76673095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD7CAYAAACG50QgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA+PElEQVR4nO3dd2AU1f738feW2d30upsCIaGISL+iQACDioQauj4gxQqoFEVBEAHLVS8qyk+uyFUv4BVURDBIDSoqVwwYxSsQBaUkCAmk92T7Pn9ExoCFAIEE9vv6JzO7Zydn22fPnDlzRuPxeDwIIYTwCtr6roAQQohLR0JfCCG8iIS+EEJ4EQl9IYTwIhL6QgjhRST0hRDCi0joCyGEF9HXdwXOVFRUgdstpw4IIURtaLUaQkL8al2+wYW+2+2R0BdCiItEuneEEMKLSOgLIYQXkdAXQggvIqEvhBBeREJfCCG8iIS+EEJ4EQl9IYTwIg1unL64NIKCFQyKCbvDSkmxo76rI4S4RKSl76UMion/e7cPBsVU31URQlxC0tIX5y0w2IBRMWJz2Cgtttd3dYQQtSAtfXHejIqRh9b2xagY67sqQohaktAXQggvIqEvhBBeREJfCCG8iIS+EEJ4EQl9IYTwIrUK/VdeeYX+/fszYMAAli9fDsBjjz1GYmIigwcPZvDgwXzyyScApKamkpSURGJiIgsXLrx4NRdCCHHOzjpOPy0tjV27drF+/XqcTif9+/enZ8+epKens3LlSiwWi1rWarUye/ZsVqxYQVRUFBMnTmT79u307Nnzoj4JIYQQtXPWln7nzp15++230ev1FBQU4HK5MBqNZGdnM3fuXJKSkli0aBFut5u9e/cSGxtLTEwMer2epKQkUlJSLsXzEEIIUQu1OiNXURQWLVrEsmXL6Nu3Ly6Xi65du/L000/j6+vLxIkTWbNmDb6+vpjNZvVxFouFnJycc6pQWJj/uT0DccHM5oAGsQ0hxMVX62kYpk6dyvjx47nvvvvYuXMnixcvVu8bO3Ys69ato2/fvr97nEajOacKFRSUy4XRL4GaIZ2XV1Zv2xBCXBitVnNOjeWzdu8cPnyY/fv3A+Dj40NiYiKbN29m69atahmPx4NeryciIoL8/Hz19tzc3NP6/IUQQtSvs4b+8ePHmTNnDna7HbvdzrZt27j++ut57rnnKCkpweFw8P7779O7d286dOhARkYGR48exeVysXHjRhISEi7F8xBCCFELZ+3e6dmzJ3v27GHIkCHodDoSExOZPHkyISEhjBo1CqfTSWJiIgMHDgRg/vz5TJkyBZvNRs+ePf+wy0cIIUT90Hg8ngbVgS59+peG2RzA/73bh4du33pBffoPre3L/w1PkT59IepJnffpCyGEuHJI6AshhBeR0BdCCC8ioS+EEF5EQl8IIbyIhL4QQngRCX0hhPAiEvpCCOFFJPSFEMKLSOgLIYQXkdAXQggvIqEvhBBeREJfCCG8iIS+EEJ4EQl9IYTwIhL6QgjhRST0hRDCi5z1colCCPFXgoL9MCjV7Ue7w01JcUU910j8FQl9IcQFMShaln6YC8A9wyz1XBtxNrXq3nnllVfo378/AwYMYPny5QCkpqaSlJREYmIiCxcuVMvu37+f4cOH06dPHx5//HGcTufFqbkQQohzdtbQT0tLY9euXaxfv561a9eyYsUKDhw4wOzZs3nttdfYvHkz6enpbN++HYAZM2Ywd+5ctm7disfjYfXq1Rf9SQghhKids4Z+586defvtt9Hr9RQUFOByuSgtLSU2NpaYmBj0ej1JSUmkpKSQlZWF1WqlY8eOAAwbNoyUlJSL/RyEEELUUq369BVFYdGiRSxbtoy+ffuSm5uL2WxW77dYLOTk5PzudrPZTE5OzjlVKCzM/5zKiwtnNgc0iG2IK4N8Fhq2Wh/InTp1KuPHj+e+++4jMzPzd/drNBo8Hs8f3n4uCgrKcbt/vx1Rt2p+MfPyyuptG+Lyd2bIy2fh0tJqNefUWD5r987hw4fZv38/AD4+PiQmJvL111+Tn5+vlsnNzcVisRAREXHa7Xl5eVgscjRfCCEairOG/vHjx5kzZw52ux273c62bdsYOXIkGRkZHD16FJfLxcaNG0lISKBRo0YYjUZ2794NwLp160hISLjoT+JSCgkyYDYHEBJkqO+qCCHEOTtr907Pnj3Zs2cPQ4YMQafTkZiYyIABAwgNDWXKlCnYbDZ69uxJ3759AViwYAFz5syhoqKC1q1bM27cuIv+JC4lvcHId/9K4tr7NgD2+q6OEEKck1r16U+dOpWpU6eedlt8fDzr16//XdlWrVqxZs2auqmdEEKIOiVz7wghhBeR0BdCCC8ic++ISyog2IBJMQJgddgoK5bjIkJcShL64pIyKUb6fXQPAFsGL6VMDoYLcUlJ944QQngRCX0hhPAiEvpCCOFFJPSFEMKLSOgLIYQXkdAXQggvIqEvhBBeREJfCCG8iJycJbxOQLAJk6IAYHU4KCu21nONhLh0pKUvvI5JURiw9g0GrH1DDX8hvIW09MXvBAUrGBQTdoeVkmJHfVdHCFGHvLalH/rrFbDM5gBC5SpYpzEoJp5b1QeDYqrvqggh6pjXtvR1BiPH/jkagJgp73ClXAVLWulCiL/itS39K5VBMbH0bWmlCyH+WK1a+q+++ipbtmwBqq+Z++ijj/LYY4+xe/dufHx8AJg8eTK9e/cmNTWVf/zjH9hsNvr168e0adMuXu1FgyRz5gvRcJ019FNTU9mxYwfJycloNBruvfdePvnkE9LT01m5ciUWi0Uta7VamT17NitWrCAqKoqJEyeyfft2evbseVGfhGhYTIqR2z7qC8DqwSm1njM/INiISTFgddgpK7ZdzCoK4bXO2r1jNpuZNWsWBoMBRVFo3rw52dnZZGdnM3fuXJKSkli0aBFut5u9e/cSGxtLTEwMer2epKQkUlJSLsXzEFcAk2Kg/7qZmBQ5sC7ExXLWlv5VV12lLmdmZrJ582beffdd0tLSePrpp/H19WXixImsWbMGX19fzGazWt5isZCTk3Nxai5EHTl1spacqCW8Qa1H7xw8eJCJEycyc+ZMmjVrxuLFi9X7xo4dy7p16+jbt+/vHqfRaM6pQmFh/udUvq6YzQGX5DGXUm3r91flLvY2/uy+S/naVp+stZRNw+/BZJaTtS5UQ/9eeLtahf7u3buZOnUqs2fPZsCAAfz0009kZmbSp08fADweD3q9noiICPLz89XH5ebmntbnXxsFBeW43Z5zesz5OPODmZdXds6Pq+1jLqXa1u+vyl3oNv7qta3tfRfztf2rUGqI72lDd77fJVE3tFrNOTWWz9qnf+LECSZNmsSCBQsYMGAAUB3yzz33HCUlJTgcDt5//3169+5Nhw4dyMjI4OjRo7hcLjZu3EhCQsL5PxshhBB16qwt/aVLl2Kz2Zg/f75628iRI5kwYQKjRo3C6XSSmJjIwIEDAZg/fz5TpkzBZrPRs2fPP+zyEUIIUT/OGvpz5sxhzpw5f3jf6NGjf3dbfHw869evv/CaiQt26uxcQM7QFUIAXjwNgzcwKCZeX1F93GXi2K2AhL4Q3k6mYRBCCC8iLf3LRHCQAcVgxGG3UVzi3dMayLh6Ic6ftPQvE4rByKrlfVEMxvquSr0zKQr9k+fLBVCEOA8S+kII4UUaXPfOqZMMXHYHhSWy617f6msE0KnJ1wCZgE2IOtTgQr9gZTLusgrM948BJPT/SHCwgvJrEDscVoovYhAbFBNPrq4eAfTkbZduBJBJMdA/eR4Am4c+TRkS+kLUhQYX+rURGmRCZ6juz73YewQhQQb0v/ajO+0NI3gUxcTKt6qDeMydDWMoZmCwAaMixxuEaOguy9DXGRRy//UqAJb7JnMx9wj0BiP7lgwCoN393n3SmcNlV+dZsTlO/wE0KkbGJ1efff3mUJlOW4iG6rIMfXHunDUC2+44vx9JRWfgsQ+qg/0ft0qwC3E58qrQDw0yojN45wU69DoDi1dWdwlNGrO1nmtTze5yqD9EVod3n3vg7YKD/VCU6sGEDoeb4uKKeq7RlcurQl9nMJC1eAoAjSb9s55rIww6hX7rHgRgy5BX6rk2oj4pipZP380D4JbbzWcpLS6EV4W+EAICgn0xKToArA4XZcWV9VwjcSlJ6DdQp6ZdAHA0kFFD4spgUnT8vw8PAfD+sBbIJU+8i4R+A6UYjKxZXn3QdMRdctBUCFE3ZBoGIYTwItLSFw2e3eWs1SifU7NvVpeTGTiF+CMS+pe5muPvHec5/v5iCwg2YFKMWB3nd2zCoNPTP/kZADYP/eOruEH17JsDPqweBbRp2IOUyTQe4g+EBvmhM2hx2d0Ulnjf0FDp3rnM6XUG3vpPIm/9J1Gdj6ehMSlG+n00HJNM0yAaAJ1By7GXTqIzeGf81epZv/rqqwwYMIABAwbwwgsvAJCamkpSUhKJiYksXLhQLbt//36GDx9Onz59ePzxx3E6nRen5nUsJMiA2RxASJB3nrwlhPAOZw391NRUduzYQXJyMuvWreOHH35g48aNzJ49m9dee43NmzeTnp7O9u3bAZgxYwZz585l69ateDweVq9efdGfRF3QG4wc+ecQ9Aaj+gNwqttECFE7LpdH/e4EB/vVd3XEHzhr6JvNZmbNmoXBYEBRFJo3b05mZiaxsbHExMSg1+tJSkoiJSWFrKwsrFYrHTt2BGDYsGGkpFx+ww31BiMHFg/mwOLB9V0VIS4rOp2Gd9bm8c7aPHVahfoWEuSn/hCFBMkP0VkP5F511VXqcmZmJps3b2bs2LGYzb+dKm2xWMjJySE3N/e0281mMzk5OXVc5YbjzGmXiy7Ta9eeeaEUIa4keoOWI4tOAtBsamQ916b+1Xr0zsGDB5k4cSIzZ85Er9eTkZFx2v0ajQaPx/O7x2k0mvOuXG27V+qrG0ZvMPL16wMB6DJxI2bz2Q9Uupx2dHrD75brk0ExseC96snYpo9qGJOx1dZfvffn87nwxi69i/mcz3fbl+p98Mb3u1ahv3v3bqZOncrs2bMZMGAAaWlp5Ofnq/fn5uZisViIiIg47fa8vDwsFst5Vy4v749PED/zjapZruZMmi67ncIS258+rq79WX1rMpsDSFnaH4C+92yu9XMUf6zm6/dXn4ua/uq1rc17eLmr7et0vturyeFwoyjas86ceT51CgnyQ//rCByn3U3Rnwy/vNLfb61Wo15mtlblz1bgxIkTTJo0iQULFjBgwAAAOnToQEZGBkePHsXlcrFx40YSEhJo1KgRRqOR3bt3A7Bu3ToSEhLO86nUXmiQCbM54Ncrahk4ueQZTi55xmunURbVAoKrPxcBwQ1zKKs3UBQta9bmX1D/fkhwdZ98yBkHhvUGLf/7dy7/+3euGv7i7M7a0l+6dCk2m4358+ert40cOZL58+czZcoUbDYbPXv2pG/f6nliFixYwJw5c6ioqKB169aMGzeuTipa8xKJZ9IZFHKWvETE/Y/Uyf8SV4bqk7VeZdOwyXKi1mVMr2hJfTuPbuMurymXQ4N80BmqI9Zld1JYUlXPNap21tCfM2cOc+b88VmQ69f//vKBrVq1Ys2aNRdeszPoDAp5/3oDAPN9E2r1GI/zt4t0uOyX50FW0XCcmuZBpngQtaEz6Ml55SsAIh7sXs+1+c0VvU+k0SuceG02J16bLV094oKZFIWBa95R5/cR4nJ0RYe+EEKI08mEa0LU0NBn6gwI9sGkVH9trQ4nZcUNo59Y1J1TxwIu1nEAaekLUYNJURi49i0Grn2rQXbjmBQ9Q9fuYOjaHWr416XAYF/M5gACg33rfNuidnQGPbmvblYPAtc1Cf2LRCZwE2cTEOyjTg8QEOxT39UBwKjoeCT5OMZfr6ErrjwS+heJ3mDkizcHqNM0iCvbqQA/l/A2KXoGr9nM4DWb66TVHvBrK726HtJSF39MQr+OuJ32GpM61b51H/zrHkGw7BFc1kyKnoFrVl+ULpfa10HH8LXfMnztt2i1GvkBuAKFBvn8eiLq+e8ZSujXEa3ewFdvDOSrNwaeU+teMRjZuKwfiuwRXDEaQreNQadlxNo9jFi7B5N01VwxdAY9uYs/vKD+fhm9Iy5rNUfbNBQmRU/SmrUAbBgxnMt/dhdxJZGWvrisVU+18BIDPnypvqsixGVBWvrCKzTEPQIh6oOEvvAK1XsESwDYNOz+eq7N79ldLnWeKDnpSlxMEvpCNAAGnY7Ba6ovYPPRiD5yHMCLnDkb58UmoS+EEPWo+gzcjwGwTE686P9PQv8SCA4y1GpIZm3LicuHdNuIhkZC/xJQDEY+/Xf1JRJvuXfzX5Zbt6wfAEPu3nJJ6iYuLoNOR9KadQBsGDFEum1EvZPQF+JPnN5Kd9RzbYSoGxL6QvwJg07HwDUrANg4Ymw910aIuiGhL8R5OHNee3HlCQ3yRWfQ4bK7KCyprO/q1Jlan5FbXl7OwIEDOX78OACPPfYYiYmJDB48mMGDB/PJJ58AkJqaSlJSEomJiSxcuPDi1FqIelY9wdoqBq5ZVa+TrNWXoGA/zOYAgoL9av2Y4F8fYzYHEHwOj6svOoOOky8dRGfQERr02wymoUGX9wR2tfq07tmzhzlz5pCZmanelp6ezsqVK7FYLOptVquV2bNns2LFCqKiopg4cSLbt2+nZ8+edV5xIUT9MShaFifnMGloRK0foyha1n+QD8CgW8P/tJzb5VGPpTgd7guraB3RGXScfPlHACIfbl3PtbkwtWrpr169mieeeEIN+MrKSrKzs5k7dy5JSUksWrQIt9vN3r17iY2NJSYmBr1eT1JSEikpKRf1CQhxOTmfefcvJsevAduQrpal1WnYvjKP7Svz0CsyPVhdq1VL/9lnnz1tvaCggK5du/L000/j6+vLxIkTWbNmDb6+vpjNZrWcxWIhJyenbmssxGXMpOgZtGYD60ck1XdVAFB0Gu768BcAlg9rctp9QcG+GH6dltnucFFSfOX0a3uz8+qMjImJYfHixer62LFjWbduHX379v1dWY1Gc96VO7WLJ4S3qe1nv67L1WRQdDyZnA3Ak0Oj6/z7eD7bCwvxR6v/40w5n+2Fh/ij+XV7HqdHXT6bmv/L43Sj0WvVv7V5TG391WPO9/04r9D/6aefyMzMpE+fPgB4PB70ej0RERHk5+er5XJzc0/r8z9XeXm/ncoiPwDCm9T87Nd05vegtt+Ruvgu1fX38Xy2p9VrSFueC0Dnu07Pltq+ZjVp9BpOvJAFQNSjjc779cz5v91EPNTpLx9/PvU78zE1y566T6vVEBbm/6fbONN5dZh5PB6ee+45SkpKcDgcvP/++/Tu3ZsOHTqQkZHB0aNHcblcbNy4kYSEhPP5F0IIIS6C82rpt2rVigkTJjBq1CicTieJiYkMHDgQgPnz5zNlyhRsNhs9e/b8wy6f2goNMqEzKLjscjakEELUVHN2znNxTo/47LPP1OXRo0czevTo35WJj49n/fr151yRP6IzKOQteQvz/XfWyfaEEOJKoTPoyX3tfbQBvoSPrf3AAO87q0QILxQQ7ItJ0WF1uOq7KuIcXIy59iX0hfACJkXHbWt/ZPXwy/vEor8SEuSH3qDFaa8+oUtvuPzH+OsMenIXV/ecWCYNqpNtXv6vihDisnRqWoa6mpJBb9CS/noOeoMWvUHLT4tz+GmxnCd0Jgl9IUS9UBQtW97PR5Gzbi8pebWFEMKLSJ++EJcxOUArzpW09IW4jJkUHcPW7sL06xw5QpyNhL4QQngR6d4RogE6dWUuq8NJWXFVfVdH1LHzPZu2LkhLX4gGyKToGbLmU6+8Kpc30Bn05P7zM3L/+dnZC9cx+UQJ0cDVvB6vEBdKWvpCNHAmRc/QtV8wdO0X9V0VcQWQ0BdCCC8i+4xCCHEOPE63ejETl/3yOz9CQl8IIc6BRq8lZ+FeACKmtT/tvtAgX3SGhn3OhHTvCCFEHdEZdOS88jU5r3xd31X5UxL6QgjhRST0hRDCi0joCyGEF6lV6JeXlzNw4ECOHz8OQGpqKklJSSQmJrJw4UK13P79+xk+fDh9+vTh8ccfx+msm8t7CSGEqBtnDf09e/YwatQoMjMzAbBarcyePZvXXnuNzZs3k56ezvbt2wGYMWMGc+fOZevWrXg8HlavXn1RKy+EEOLcnDX0V69ezRNPPIHFYgFg7969xMbGEhMTg16vJykpiZSUFLKysrBarXTs2BGAYcOGkZKSclErL4QQ4tycdZz+s88+e9p6bm4uZrNZXbdYLOTk5PzudrPZTE6OXJ9SCCHgt5k1Xfb67fY+55OzPB7P727TaDR/ersQ4spw6izUK9nFfI46g56cRduJmNrzov2P2jjn0I+IiCA/P19dz83NxWKx/O72vLw8tUtICHH5y8srU5ev1B8Ab3iO5zxks0OHDmRkZHD06FFcLhcbN24kISGBRo0aYTQa2b17NwDr1q0jISGhzisshLj0nC4PZnMAZnMAQcF+9V0dcQHOuaVvNBqZP38+U6ZMwWaz0bNnT/r27QvAggULmDNnDhUVFbRu3Zpx48bVeYWFEJeeXqdhQfJJAKYPjazn2ogLUevQ/+yz367wEh8fz/r1639XplWrVqxZs6ZuaiaEEKLOyRm5QgjhRST0hRDCi0joCyGEF5HQF0IILyKhL4QQXkRCXwghvIiEvhBCeBEJfSGE8CIS+kII4UUk9IUQwotI6AshhBeR0BdCCC8ioS+EEF5EQl8IIbzIOc+nL4QQVyKP061eLctld9VzbS4eCX0hhAA0ei0nX8wEIHJGXL3W5WKS7h0hhPAiEvpCCOFFJPSFEMKLXFCf/rhx4ygoKECvr97M008/zS+//MKSJUtwOBzceeedjB49uk4qKoQQ4sKdd+h7PB6OHDnCF198oYZ+Tk4O06ZN48MPP8RgMDBy5Ei6dOlCixYt6qzCQgghzt95h/6RI0fQaDSMHz+egoICbrvtNvz8/OjatSvBwcEA9OnTh5SUFCZPnlxX9RVCCHEBzrtPv7S0lPj4eBYvXsxbb73FqlWryM7Oxmw2q2UsFgs5OTl1UlEhhBAX7rxD/29/+xsvvPACvr6+hIaGMmLECBYtWvS7chqN5oIqKIQQou6cd+h/++237Ny5U133eDw0atSI/Px89bbc3FwsFsuF1VAIIUSdOe/QLysr44UXXsBms1FeXk5ycjIvvvgiO3fupLCwkKqqKj7++GMSEhLqsr5CCCEuwHkfyL3pppvYs2cPQ4YMwe12c/vtt9OpUyemTZvGuHHjcDgcjBgxgvbt29dlfYUQQlyACxqn/9BDD/HQQw+ddltSUhJJSUkXslkhhBAXiZyRK4QQXkRCXwghvIiEvhBCeBEJfSGE8CIS+kII4UUk9IUQwotI6AshhBeR0BdCCC8ioS+EEF5EQl8IIbyIhL4QQngRCX0hhPAiEvpCCOFFJPSFEMKLSOgLIYQXkdAXQggvIqEvhBBeREJfCCG8iIS+EEJ4kYsS+hs2bKB///707t2bd95552L8CyGEEOfhgi6M/kdycnJYuHAhH374IQaDgZEjR9KlSxdatGhR1/9KCCHEOarz0E9NTaVr164EBwcD0KdPH1JSUpg8eXKtHq/18z19PcD/T5YDzigXqC7rAoJqLAefVk4XEFpjOfy0+/QBFnVZ+ZNlAEONdYP/b8tG/9PLmWqs11z2OaNczXXf05YjTivnV2O95rK/3+nlaq7XXA44o1xgjfXAM+4LqrEe7PvHywChNdbDaiybfU4vZ/Ex11gO+23ZN/T0cr4hNZaDaywHnVEuqMZyYI3lgDPKBfzJsv8Z5fz/ZNnvjHJ+f3Gf71mXq9d9/mTZdEa539bNpy0bTytXc93sa6ixrJxRTqmx/NtXP8xXd1q5kBrrwTWWA88oF+D7W0eBf41lP9/TOxB8a6z7nHFfzXWT32/LRr/Ty9VcN/j/8TKAUmNdH1Bz+fS66wJ1f7KsP6Ocvsbyb6+fNvD011Yb+Nvrrg2ouXz6e1VzXRtg+sPl6nWfP1yuXvc9bVnrd/r9Z6PxeDyec3rEWbz++utUVlYybdo0AD744AP27t3L3//+97r8N0IIIc5Dnffp/9FviEajqet/I4QQ4jzUeehHRESQn5+vrufm5mKxWP7iEUIIIS6VOg/9bt26sXPnTgoLC6mqquLjjz8mISGhrv+NEEKI81DnB3IjIiKYNm0a48aNw+FwMGLECNq3b1/X/0YIIcR5qPMDuUIIIRouOSNXCCG8iIS+EEJ4EQl9IYTwIhL6QgjhRep89M6F2LBhA0uWLMHhcHDnnXcyePBgRo4cyb/+9S/WrVvHli1bAPD396esrAyNRsOIESO46667eP755ykqKiI7O5uCggL0ej1lZWUYDNWnREdERFBcXKz+r4yMDEwmE2azmaCgIPLy8jh58iSjR49m1qxZbNu2jYceegiz2UyfPn348ssviYuLo1u3bixZsgRfX18MBgNGo5EDBw4QFRVFQkICX3/9Nf/617/4+OOPWbBgAZGRkQQEBFBRUcHJkyeJjo4mLCyM9PR0GjdujE6n4/DhwxiNRnx8fKisrMTlcqHT6TAajfj5+VFVVYXb7Uar1RIaGkpOTg5BQUHY7XbKysrU+0wmExqNBo/HQ3h4OFarVX0t7HY7Ho8Hj8eDj48PbrebyspK9Ho9Op0Om82Goij4+vqi0WjUeiiKgqIo+Pn5UVxcjMPhwN/fn3vvvZd3332X8vJyqqqq1O0YjUYqKipwOp34+fkxceJEUlNTSU1NRavVoigKTqeTgIAAbDYbVqsVt9tNWFgYbrebwsJCAMLCwujevTv5+fns3buXqKgonE4nhYWFBAcHYzAYuOaaa9BoNAQEBLBp0yacTifXX389DoeD77//Xj0/pHXr1gwYMIDp06fjdrvR6XRER0djMpk4fvw4fn5+ZGdnYzKZaNSoETk5OZSWluLn56e+rkVFRdjtdkwmE0FBQeTk5KDVagkPDycoKIijR49iMpmoqqrC4XDg5+eH0WiksLAQnU5HaGgooaGh5OXlUVxcjE6nw+FwoNfrCQkJUc9t0Wg06PXVX0u73Y5Go0Gr1ap1OfV6KYqCXq9HURQ8Hg8BAQEUFRURHBysvidOpxMAk8mEj48PDoeDwMBA9Ho9WVlZaLVaXC4Xbrcbl8uFj48Per2ekpISddtWqxWNRoPb7Vbf46qqKrRaLb6+vlitVpxOJyaTibi4ODIyMnC5XAQGBlJSUoLL5VK/J2VlZWi1WoKDg6moqECr1WK32wFwuVzqNsvLywHQarV4PJ7TTu70eDzo9Xr1edbcvkajwW63YzabKS8vx+PxoNVqKSsrw+FwoNFo8PHxwWg0UllZicViwcfHhwMHDhAYGEhFRcVp3xFFUSgsLFS/A6deC4PBgMPhQKfT4evri1arpaKiArfbrb5/0dHRmM1m9uzZg16vV9/T0tJSAHQ6HTqdjqioKCwWC4cOHSIvLw8/Pz9MJpOaVYqi4HK51OftdDpxuVwAtGjRAoPBoL4fLVu25Omnn8bP7/TpQc7UYFr6pyZqe/fdd/noo4946623GD58OJmZmezevZsdO3aQnJzM448/zuHDh5k6dSpr165lxYoVrF27luTkZDweD0eOHOGjjz7i1VdfxeFw8NZbb7FhwwYcDgcPP/wwH330Ec888wwOh4NVq1Yxa9Ys9u3bh9PpxO12s3//fhYvXszUqVNxu908+uijvPfeexw6dIjPP/+cxYsXk5ubyz//+U+mTJlCeno6LpeL6dOns2bNGo4cOcJnn33GSy+9hMvlYuHChcyaNYvs7Gw8Hg8zZszg4MGDOJ1OHn74YdxuN263m9tvv53IyEjcbjdDhgxBr9fTqlUrysrK1MCIjY2loqKC8vJyunbtqn7AHnzwQbRaLQaDgeDgYGJjY4mPjycrK4vo6Gj1iz5v3jyCgoIICwvDYrHQp08fRowYoX4R/f39CQ0NxWQyqfVwOp106dKFoqIiHA4Ha9asITY2lpdffpns7GyMRiMvv/wyTqeT6667DqvVisvlYu3atcTGxrJ48WJ27tyJoijMnz8fp9PJqlWrcDqd2Gw21q1bR2JiIlVVVYSFhaHRaHj11VcxGo0cPnyY1NRUunfvzuzZs8nIyCA0NJQnn3ySzMxMPv/8c7Zs2cKaNWtwuVz06tULo9HIf//7X7p3786cOXP45ZdfOHLkCM8//zxWqxWtVkuvXr2YOXMme/fu5aqrruKpp55Cp9MRGRnJqlWrKC8vx2AwcPPNN2Oz2SgqKmLt2rWEh4czZswYSktLCQsLY9euXRiNRmw2GzabjUaNGvHtt98SHh5OTEwMgYGBhIeH8/XXX6MoCmPHjqWwsBC9Xs93331HeHg4GzduxOPxEBISwnfffUfHjh1ZtGgRvr/O1/Pvf/+b0NBQAgMDMRgMOJ1OnnzySex2O76+vtjtdiIjI3E6nRQXF/O3v/0Ng8GA3W7ngQceQKfTqT9GkZGRJCUlcfDgQSIiIggPD8fhcDB37lyCg4OJiIjA4/Fw4403Mn78eGw2G4GBgQQFBXHNNdcwffp0nE4nISEhfPbZZ7jdboYNG0aTJk3o0KEDt9xyC1D9w6UoCu+99576WdRoNMTExPDll19isVjw8/PD398fg8HA8uXLiY2NZdu2bSiKQlRUFDt37qRHjx6EhISwfv16NBoNs2bNQqPR0K5dO6qqqrDZbCxYsED9caiqqqJz585qnvTs2ROHw0FVVRV///vf0emq59gpLy+nS5cuDBw4kPT0dAICAmjdujUOh4MXX3yR6OhoQkJCsFqtjBkzhpEjR2K1WjGbzUREROBwOHjmmWfUHySDwYDJZKJdu3bodDpatWpF27Zt2bVrl/qjaLFY1PDv3LkzWq2W5s2b07VrV/73v/+pP+SRkZHqazBp0iQ0Gg3x8fHcdNNNaDQannjiCfR6PXFxcUyePJmDBw9y7bXXsmHDBlq1asXChQvPmrUNJvRrTtTm6+uLv78/1157LRaLhbCwMGbNmoXBYKBbt24MHDiQnJwcCgoKcDgcrFy5kvvuu4/y8nI0Gg3jx49n1KhRNG3aVH0RFy5cSIcOHQB49tln1dbBDz/8gEaj4d577yUiIoLOnTuzatUqWrZsSUREBCkpKXTo0AFFUYiIiKB3796EhYXh6+vL9u3bue222/Dx8eGjjz4iPDyckJAQXnvtNcaOHQvASy+9xP3334/FYsFisbBp0yZeeOEFdTkyMhKNRkNkZCS33HILQUFBNGnShO7du6st1VatWpGQkEBQUBAWi4WQkBDcbjdTp06le/fuKIrC/fffj6+vL126dKG8vJwdO3aoH+TCwkJ8fHxYuHAhgYGBXHPNNdxwww3MmzePvn37EhAQQMeOHdFqtbRo0YJBgwYRFBTEVVddRUhICO3atVP3MoKDgzEajeh0Otq1a8edd95J69atCQkJoVWrVvTu3ZuQkOpJ04qKirBarUydOhWHw8EHH3yAy+Vi8eLFtG3bltDQUAICApgwYQK+vr7ExMTg41M9eZTD4eDQoUNERkai0+l4/vnn8fX1paioiIULF9KmTRvcbjc33HADfn5+PPDAA9jtdn744QdatGiBVqvlpZdeIjIykuPHj3PXXXfhcDiIjIzk008/5aGHHiI8PJzQ0FAWLlzIAw88QLNmzXjllVfweDwkJiZSXl6O2+3G4/EwefJkrFYrW7dupbKyEpvNxoMPPkhOTg4mk0ltNQ8aNAir1UpRURHFxcVYrVYmTJigNmpOtbivu+46CgoKGDVqFDabTQ3p4uJidu3apX6Wp0+fTmxsLDabjdDQUIYOHUrjxo2Jjo7G39+f/v37qz+WZrOZG264gRtuuIGhQ4cycuRI7r//fiIiIujVqxdWq5X33nuP66+/nqCgILKzszGbzSxevJjAwEASExPp168fzz77LACNGjVi9OjRaLVapkyZQlhY9UR5AwYM4NixYzRp0oTNmzfz8MMPM2zYMP79738zZswYWrduzR133MELL7zAtGnT6NKlCyaTiUceeQSdTkdmZiYmk4lJkyZht9uZMmUKdrud559/Ho/Hw8yZMwkNDaW0tJSHHnqIN954A5PJxJo1azAYDJSWlhITEwOg7o1WVVXh8XjUH0KobiVPnz4dqN7bmTdvntq4y8/PZ8uWLepexI8//ojb7Wb+/PmUlJRgMBjweDz8v//3/xgyZAhut5sWLVrgdrsxGo1ER0fj5+dHcHCwettPP/1E+/btMZlMbNu2jbi4OMLDwxkyZIj6fj3zzDOcPHmStm3bkpWVRUlJCUajkdjYWBwOB8XFxeTl5ak9Ge3bt8fPz4+4uDjat2/Pf/7zH/X7unr1anx9fYmOjgbgpptu4tNPPz1r1jaY0M/NzcVs/m0mxttvv13dJYqLi6Njx44AZGZmkpKSwtGjRxkwYAB6vZ4ZM2YQGBiI3W4nPj6exYsX06NHD3766SeGDRvGoEGDePfddwkKCiI1NRWHw8H06dPp168fb7zxBoqi0L9/fzweD6mpqQQHB9O8eXMApk+fzsSJE9FoNLRp00Z9UwEeeeQRduzYgUajYefOnTRp0oSqqiruvfde2rRpg1ar5dFHH2XChAk4HA7y8vI4cOAAX375JVqtlpEjR3L48GGCg4N58cUXefvttykuLqZt27akpaVx6NAhnE4nqamp3H777dx5551qt1V8fDzXX389aWlpdOzYkZUrV3LixAnWr19PZWUlgwYN4pdffiEoKIi//e1vOJ1OxowZQ1FREVu3bmX79u3885//pKqqipycHB5++GEeeOABtm7dyqpVqygoKODll18mPj6e9957j4qKCrp168b777/P//73PzX8f/75ZwYMGECnTp1YsWIFmzZtIjo6muHDh3Ps2DHatm1LVFQUiqLw/fff079/f7755ht27tyJVqtl6NCh3HrrrbRt25b09HR69OjBpEmTyM/PJzw8nIqKCr799luGDh0KVO8eT5s2jV69euHxePjxxx8ZPHgwgYGBfPfddwB07NiRnTt3cuTIEYqKijCbzaSkpKAoCoMHDyYgIACz2YzT6eSzzz6joKCAbdu24fF4eOedd5gyZQpbtmxh+/bt6HQ6/Pz8GDduHMBpU4qMHTuWhx9+mGPHjqHX63nppZeYPXs2brebsrIyHnnkEWw2G3v37lUDMzAwkKioKF588UV8fX0pLS2lWbNmVFZWkpmZSY8ePdiwYQMGg4Hp06dTXFzMN998Q1VVFT/99BP79u3j6aef5tixY2RlZaHX68nPzyc7O5vKykqWLVtGSkoKP/74I1OmTOGVV17h+PHjrF+/nmPHjlFeXk5+fj6HDh3C7XYTHByMoigcPXqUpUuXsmXLFoYOHcrbb79NVlYW3333HQaDgUmTJqmheccdd3Dy5EkKCgqw2+3069ePvLw89Ho9jz76KEZj9UySVquVLl26sHTpUvz8/CgrK+PGG2/E5XJx33334e/vj4+PD1FRUWzZsoXdu3djs9nYuHEjN998M7/88gt/+9vfSEtLY9y4cRw8eBCtVsvhw4c5cOAAcXFxPProoxQWFqLRaJg2bRopKSlkZWURGBjI6tWrmT9/PldddRWPPvoojz/+OKGhoXg8Hr7//nuOHj1K06ZNKSoqorS0lKZNm5KXl0dJSQknTpzAz8+PQYMGcccdd6DVaklLS6OoqIjy8nKmTp1KUVERbreb0tJSPB4PFRUV7Nmzh9LSUoxGIydOnMDpdNKyZUtOnjxJdnY2r7/+OnFxcXz99ddUVFSg1+spLy/HarWqXX2nuo7ef/99du3axc6dO2nVqhV79uzhyJEjPPXUUyQnJ7Nr1y6Ki4vp1KkTAFu2bDltCpw/02BCvzYTtR08eJC7776bmTNnMm/ePGbMmIHb7ebYsWNAdT/wCy+8gK+vr7or1bZtW1avXs2+fftITk5m1apV9OnTh7Vr1/L555+za9cuGjVqxMCBA8nPz1d30c4mPz+fO+64g+HDhxMUFMS6detwu93YbDb69u2r7s4FBwej0Wiw2WxotVreeOMNqqqqKCsrY+PGjQwePJiysjKWLl3Kzp07adu2Lffccw8BAQFERERgtVqZOXMmcXFxZGVl8cMPPxATE4PT6eTuu+/mvvvuY8aMGVRWVvLUU0/xyiuv4HA4WLp0KSNHjsTj8XD06FFmzZpFYWEhxcXFNGvWjM2bN5OTk8OUKVNITEyksLCQZ599lhkzZrBz5066deuGyWTi008/pXnz5vj7+3PixAkiIyNZtGgRNpuNvLw8hg0bxkcffcTnn39O586dSUtLw2g0Mnv2bCIiIsjNzeXHH3+kffv27Nq1i7y8PHr06KF2p0ydOpX+/fuTlpZGs2bN+Pnnn5k8eTIWi4XGjRtjNBopKirigw8+UPto4+PjAXA6nfj4+NCiRQtSU1MpKiriuuuuw+12ExISwqpVq9BqteTl5REZGYnFYuHIkSP4+PgwcOBACgsLCQsLY9u2bYSGhrJjxw6aNGnChg0buPfeexk4cCBTp06lcePGrFu3Dj8/P7799lv0ej2TJ09m165d+Pn50bJlSxRFwcfHh+joaPR6PR07duTWW2/lkUceUY+1XHfddTRv3pzOnTuTmJjIlClTuOaaa8jIyGDSpEncfPPNHDp0CL1eT9OmTdmwYQMDBgwgLCxM3cs7cOAA5eXlNGvWDIfDwdatW5kwYQKhoaFUVVXRsWNHevXqxaFDh8jIyGDChAkoikJISAjBwcHExMSQnZ1NaGgogwYNIjMzk759++Lj44PH48FgMHDttdeiKAoajYYOHTqg1+vp0KEDTZs2pWXLltx22228+uqr6t4HwBdffEGjRo3U78fnn3/OsGHDuOOOOwgJCWHy5MncdttttGnTBj8/P7KysrBYLCiKwvjx49XjCXa7nVmzZtGmTRuaNWvGvHnzGDx4MP/5z3+4++67iY2NZcSIEbRt25bMzEyCg4OJjo7G4/Hw5ptvsmLFCiIjI6msrCQhIYGlS5eSlZVFWFgYSUlJNG7cGH9/fywWC506dSInJwd/f39WrVqlfqdP9Z1rNBrGjh1LREQEWq2WcePG0ahRI2JjY9HpdISHh5OVlaUeawLo1KkTBw8epLS0lE6dOlFcXMzy5cvp0aMHbrebEydOUFpayg033IDD4WD9+vV06dKFw4cPA9CvXz8ACgoKKCgooEePHpSVlfHss88SFRWFx+PhkUce4bbbbqN79+7ceuutPPDAAwwfPlx9Pc+mwYT+2SZq2717N3feeSdjxoyhVatWAHz66adqv/miRYv4+OOPmTJlCgDh4eHExsbi7++PyWSiV69e/O9//+Obb77B5XIRHx9PWFgYdrudcePG0aZNG8xmM0ajkZiYmN/VpeYPgcPhYOrUqfTq1YuuXbsC1QdmTu3ijx8/nkcffRS73c7TTz9NeHg4cXFx6kG5fv36YbfbSU1NVX8coqOjSUtL4/Dhw5jNZubPn09aWhq+vr4MHTqU3bt3M3/+fHVP4/nnn2fMmDG8+eab5ObmcscddzB06FBWrlxJYWGh+oFKT09HURSaNGlCcnIyjRs3pnnz5nz//fd88803eDwe+vXrx6RJk2jdujU33XQT+/btY+zYsQQGBnL77bdz8uRJtFot7du356effqKkpITIyEhKSkrIzs5mzJgxdOjQgZCQED755BPat2/Pvn37AMjLy2PlypV8//33TJkyhfbt2/PJJ58QEBDA9ddfz8GDB0lKSqKqqorMzExatmzJd999h8vl4ocffiAvLw+n00lubi6VlZU4HA66du3K8uXLsdls/PLLLyxcuJCNGzdis9n49NNPWb9+PRkZGYwbN47y8nKKi4tJTk4mKyuL5ORkMjIyeO211wDIzs6ma9eupKenU1lZyS+//MLx48dJTk7m448/5ptvvuHnn39m5syZ3HjjjVgsFoxGIxkZGej1enJzc3G5XLhcLtLT0xk9ejStW7cmICCAtWvXkpGRQbt27XC5XHz22Wd8/fXXfPzxxzz44INkZGTg4+NDSEgIubm5GI1GbrzxRnJzc0lPTyc+Pp7GjRsTFxfH1VdfjVar5frrrycmJga73U54eDjBwcFYrVZCQkLUA9IGgwG3201ERAQ9evSgZcuWBAYGotVqycjIAOD48eN89dVXtGvXjv/85z80bdqUwMBAgoODGTJkCCUlJbRu3ZqtW7fSqlUr+vXrx8GDB5k0aRJhYWE8+eSTVFRUcPXVV2O329m/fz9XX301AG63mx9//JE333yTQYMGkZ+fT0hICHa7nfT0dAwGAytXrmTGjBkUFRWRkpKC3W6nsLCQ0NBQIiIi+Pbbb7njjjvYv38/YWFh6sH/+Ph4Ro0axbFjx+jVqxdNmzbFZrMRFBSkHvPQ6XSYzWaysrLUPTiAgQMHEhkZiclkQq/X8/XXX6st9HvvvZeuXbuycuVK9SC/wWDgtttuIzMzk/bt23Pw4EEURWHChAlcc801LFmyBJfLxU033URYWBjNmzenTZs2JCQk0LZtW9q0aUNsbCwjR47kgw8+IDo6mpdffpklS5bQpk0bNeD379+PXq/H5XLxwQcf0LRpU5o0aaJur1+/fgQEBGC1Wmnbti3NmzcnLi6Oxo0bc+utt+J0Olm7di1t27ZVu73+SoMJ/b+aqC03N5dJkyaxYMECmjdvzpw5c7Db7bz++uu0bNmSuXPnMnXqVNq1a8fx48ex2Wx06dKFffv20a1bN1wuF19++SVhYWHExcXRrl07UlNTqays5Pjx47z44otqH/HmzZu5/fbbycjIUPv/Nm7cqO6y2mw2CgoKuOuuu+jfv7+6t+HxeNSROm+++aZ60ZhTfZo//fSTuo3PP/8cvV6PzWYjPj4eh8PBwYMHefDBB7Hb7bRt25ZJkybRuHFj9Ho933zzDZMmTaJp06b0799f3eNZvnw5VVVVPP744yQnJ/Pzzz+zd+9eunXrxrhx46isrCQuLo6KigoeeOAB5s2bR05ODldddRWTJk2iffv26PV6nnrqKR577DHy8vL44YcfeOKJJ3j44YexWCy88847uFwu9dhJu3btWL9+PeXl5VRWVvL888/Tr18/0tPTiYyM5B//+AfvvPMOXbp0oWvXrmoYeTweBg0axDvvvENsbCxVVVWsXLmSDh06sHnzZvWA9p49e3juuedo2bKleryif//+7NixA0VRaNWqFbt27aJZs2a0adNG7eK75ZZbGDJkCFu3bsVoNNK7d2927dpFz549iYuL44MPPkCr1TJ9+nQGDRpE//79MRgM3HjjjezatYtrr70WjUbDZ599hp+fH6NGjaJdu3bs378fl8vFoUOHSE5OplmzZrjdbpKTk+natStbtmzh5MmT6gHR0aNH891339GiRQtee+01kpOTueeee2jWrBl+fn74+Pig0+no1asXycnJZGdnqz9KN9xwA5s2bVL753fs2EHHjh3Zt28fNpuN8vJy9u3bR9euXTl27BgGg4HCwkLWrVtH3759qaioICwsjI8//hiAxMREpk+fTmlpKSUlJVx33XUMHz4cgOjoaBwOB/v27WPMmDEcOHAAHx8fCgsLWb9+PXq9noMHDzJixAj27NnDhg0bCA8PZ/bs2bRq1QqdTofb7SY+Pp79+/ej0+m4+eabgeoDpTabjWnTptG1a1eioqKYO3cu3333HW3atKFHjx7cd999DBs2DI1Gw7PPPssPP/yAoijY7Xa++uor4uLi+Pzzz9HpdFgsFjweD02aNCE1NZVNmzZRUVFBWloa7du3p7y8HKPRiNVqZc2aNXTp0oX8/HwiIiLYtGkTLpeLhIQEZsyYQVZWFlarlYEDB9K9e3f0ej0+Pj7Y7Xa+/vprRo4cycmTJ9WRSSkpKbjdbg4dOkRUVBTZ2dnMnz+fNm3acPfdd6PVatW9r8aNG7Ns2TKsVistW7Zk2bJlREdHs3z5chwOBy6XixkzZvDVV1+xbNkydDodCQkJlJWVMW/ePPU74Ha7OXnyJDExMSxbtgyTyUR0dDRZWVk8+OCDZGdn884779C/f3/uuecerr76ajweD8uWLaN///5nzdoGNffOhg0beP3119WJ2saPH8/NN99M586d2bp1K02aNAGqW48ajYbQ0FB1N/nDDz8kLS2NyMhItm7ditvtpk2bNvz88884HA66d+9Op06d+PTTT1m4cCFvvPEGH374oTr0zWq1cvToUSZPnswDDzzAzp071YO7t9xyC5988glt27ZFURQ2bdpEs2bNMBgMFBUVkZeXp45S+OKLL1ixYgVZWVncddddNGrUCI1GQ6tWrdi2bRuRkZG0b9+etLQ0zGYz69ato0uXLjidTioqKtThYG63Gz8/P0JDQ8nOzsblcp12gDQoKIiSkhIA9djHqaFcQUHVV5U6NfROr9dTVVWlDjE7NRzT19cXm82Gx+PBbDaj1WrVIZ5Op1PtTvH19cXPz4+CggJ1KObo0aNZsWKF2n95ai/n1BAzt9uNj48Pt99+OydOnFDD7NSwuVMHZZ1OJ4qi4O/vz6233soHH3xAcXEx/v7+dOrUCYPBwH//+191xNHPP/+sHgCOjY0lJyeHtLQ0IiIiqKysVMMsLy+PqKgojEYjTZo0Ydq0adx6660oikJ5eTl9+vQhPDyc1atXEx4ejsvlIisri3379rF9+3bmzZtHZWUlAQEB2O12dZilwWDAYDCow1L9/f25//77efHFF3E6nepQx1MtzlPvi4+PD5MmTWLnzp189dVXeDwe9XgBQGVlpfqYpk2bcuONN/L+++9TWlqqHig+NWTz1Pa0Wi06nQ6Xy0VwcDAFBQVotVpKSkrw8fFR90D0ej1BQUHYbDZCQkLw8fEhMzMTX19fKioq1PfNYDCg0+nUz8e1115Lfn4+xcXFVFRUoNPp1ONWp0Y4+fv7U1hYiJ+fHykpKWg0Grp160ZhYSFXX301paWllJWVce2113LgwAEqKytJSkpi9uzZLFmyhOXLlxMVFUVJSQmBgYHMnDmTp556ipKSEjp06EBZWZnawKmoqKCkpITKykr8/PwoKSlRvydabXX71W63ExUVRX5+Pi6Xi7KyMkwmkzrsUaPREBgYiNVqVQcJHDlyBLPZTGFhIS6XC6PRiKIoaLVade/ymmuuoby8HLvdTkFBgTo809/fH7fbjcPhUIfgnhrK27RpU3bu3InVaiUiIgKXy0VxcbH63TiVYc2bN+fw4cMcP36csLAwHA4Hdrtd/Tx5PB5CQ0PJzc2lSZMm6pDWoKAg9TMBEB8fz+OPP37WLp4GFfpCCCEurgbTvSOEEOLik9AXQggvIqEvhBBeREJfCCG8iIS+EEJ4EQl9IYTwIhL6QgjhRST0hRDCi/x/UGOftvhOKTQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_text_length = length_distrubtion(dataset['original_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9affb83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outline_1_text_length = length_distrubtion(dataset['outline_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e3c260c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outline_2_text_length = length_distrubtion(dataset['outline_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac05e8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outline_3_text_length = length_distrubtion(dataset['outline_3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8c1dfc",
   "metadata": {},
   "source": [
    "## Insights after bar-plot\n",
    "We can notice that outline 2, 3 have some empty text scattered across. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b2f3f3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_plot_pearson(original_text_length: list,outline_text_length: list)-> None:\n",
    "    print(f'Correlation coefficient is : {stats.pearsonr(original_text_length,outline_text_length)}')\n",
    "    pyplot.scatter(original_text_length,outline_text_length)\n",
    "    pyplot.xlabel(\"Length of original text\")\n",
    "    pyplot.ylabel(\"Length of Outline\")\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2931a49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_ratio(original_text_length: list, outline_text_length: list) -> int:\n",
    "    average_ratio = 0\n",
    "    \n",
    "    for i in zip(original_text_length,outline_text_length):\n",
    "        if i[0] == 0 or i[1] == 0:\n",
    "            continue\n",
    "        average_ratio += (i[1] / i[0])\n",
    "    \n",
    "    return average_ratio / len(original_text_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "41da116e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation coefficient is : (0.601260144328335, 3.7257864147540507e-11)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Ratio between original length and outline length: 0.7739341282370215\n"
     ]
    }
   ],
   "source": [
    "calculate_and_plot_pearson(original_text_length,outline_1_text_length)\n",
    "print(f'Average Ratio between original length and outline length: {calculate_average_ratio(original_text_length,outline_1_text_length)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "00ac8e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation coefficient is : (0.5884883878516578, 1.2038501461187022e-10)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Ratio between original length and outline length: 0.8125309379712194\n"
     ]
    }
   ],
   "source": [
    "calculate_and_plot_pearson(original_text_length,outline_2_text_length)\n",
    "print(f'Average Ratio between original length and outline length: {calculate_average_ratio(original_text_length,outline_2_text_length)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8afa0f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation coefficient is : (0.37490400049574074, 0.00012151056023146377)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Ratio between original length and outline length: 0.6328576048403345\n"
     ]
    }
   ],
   "source": [
    "calculate_and_plot_pearson(original_text_length,outline_3_text_length)\n",
    "print(f'Average Ratio between original length and outline length: {calculate_average_ratio(original_text_length,outline_3_text_length)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0921b0",
   "metadata": {},
   "source": [
    "## Insights after scatter-plot\n",
    "We can start noticing specific pattern where the distrubtion of the scatter-plot is common between them all which is roughly ranges between 0.6:1 and 0.8:1 or 1:1.25 and 1:1.667 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f972189",
   "metadata": {},
   "source": [
    "## One step further\n",
    "As a final check for the data analysis, we are going to check the normal edit distance between the Original text and the Outline to have a gesture about how much different the text is. As a more complex measurement we are going to use a Sentence Transformer to calculate a sentence representation embedding and calculate cosine similarity to find out how similar they are in terms of context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aba55ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edit distance for Outline 1 and Original Text: 0.2601910128717278\n"
     ]
    }
   ],
   "source": [
    "edit_distance_average = 0\n",
    "# Edit Distance is 1 - Similarity (How much we need to change the text to be 100% similar)\n",
    "for i in zip(dataset['original_text'],dataset['outline_1']):\n",
    "     edit_distance_average += 1 - Levenshtein.ratio(i[0],i[1])\n",
    "      \n",
    "print(f'Edit distance for Outline 1 and Original Text: {edit_distance_average / len(dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f5312f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edit distance for Outline 2 and Original Text: 0.16992249960771214\n"
     ]
    }
   ],
   "source": [
    "edit_distance_average = 0\n",
    "\n",
    "for i in zip(dataset['original_text'],dataset['outline_2']):\n",
    "     edit_distance_average += 1 - Levenshtein.ratio(i[0],i[1])\n",
    "      \n",
    "print(f'Edit distance for Outline 2 and Original Text: {edit_distance_average / len(dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ee2c5f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edit distance for Outline 2 and Original Text: 0.3802138721446551\n"
     ]
    }
   ],
   "source": [
    "edit_distance_average = 0\n",
    "\n",
    "for i in zip(dataset['original_text'],dataset['outline_3']):\n",
    "     edit_distance_average += 1 - Levenshtein.ratio(i[0],i[1])\n",
    "      \n",
    "print(f'Edit distance for Outline 2 and Original Text: {edit_distance_average / len(dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "11ab90ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "06b9d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpnet = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1644e28c",
   "metadata": {},
   "source": [
    "## Contextual Similarity Approach\n",
    "It is time to find whether the length indicates anything useful for the business case using the contextual similarity approachg. We are going to use a transformer called MPNET (https://arxiv.org/abs/2004.09297) one of the sentence transformer state-of-the-art in STS-B tasks. However the used version is fine-tuned on Paraphrashing and sentence similarity tasks while the original model is pretrained as a language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "43b8079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_embeddings = mpnet.encode(dataset['original_text'])\n",
    "outline_1_embeddings = mpnet.encode(dataset['outline_1'])\n",
    "outline_2_embeddings = mpnet.encode(dataset['outline_2'])\n",
    "outline_3_embeddings = mpnet.encode(dataset['outline_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4d6b89c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9406161308288574"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outline_1_average_similarity = util.pytorch_cos_sim(original_embeddings,outline_1_embeddings).trace() / original_embeddings.shape[0]\n",
    "outline_1_average_similarity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "45a705c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8823512196540833"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outline_2_average_similarity = util.pytorch_cos_sim(original_embeddings,outline_2_embeddings).trace() / original_embeddings.shape[0]\n",
    "outline_2_average_similarity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "38c43448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8160586357116699"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outline_3_average_similarity = util.pytorch_cos_sim(original_embeddings,outline_3_embeddings).trace() / original_embeddings.shape[0]\n",
    "outline_3_average_similarity.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f195466d",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "It seems like outline with the highest text lenght correlation and the highest sentence similarity is of the highest quality. (This assumes that high contextual similarity reflects quality while having high correlation in the text length, this can reflect that the writer increased the text lenght maintaining the same topic/context of the text)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a510d1",
   "metadata": {},
   "source": [
    "## =========================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89ce61b",
   "metadata": {},
   "source": [
    "## Text Classification\n",
    "In the next section, we are going to create a classification model for the 19 different categories we have. In the next paragraph, i am going to explain the methodology used and explain every small detail. \n",
    "First of all, pretrained language models are quite the standard now to be used for downstream tasks like text classificiaton, question answering and so on. So i am going to use RoBERTa pretrained model https://arxiv.org/abs/1907.11692 as a feature extractor returning a numeric vector having the sentence representation. \n",
    "\n",
    "The pipeline is as the following: Raw text -> RoBERTa Model -> Pooler Output -> 2-Layer Feedforward Network as Classification Layer. Moreover, i have divided the classification tasks into different piles so that the classification model would be as specialized as possible treating it as a literature critique. Finally, i changed each label to be a binary label for training conventions, for example, we have labels ranging from 0-3, so for each label such as dull_writing there is going to be a dummy label for 0, for 1 and so on called dull_writing_0, dull_writing_1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1d5f8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_roberta_model(gpu_usage):\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    model = RobertaModel.from_pretrained('roberta-base')\n",
    "    if gpu_usage:\n",
    "        model.to('cuda')\n",
    "    return tokenizer,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e5fdc70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification_Model(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim,hidden_size,num_classes):\n",
    "        super(Classification_Model,self).__init__()\n",
    "        self.ff = nn.Linear(input_dim,hidden_size)\n",
    "        self.out = nn.Linear(hidden_size,num_classes)\n",
    "        self.selu = nn.SELU()\n",
    "        \n",
    "    def forward(self,x,batch_size):\n",
    "        x = self.selu(self.ff(x))\n",
    "        x = x.reshape(batch_size,-1)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "267a8134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataset,labels,test_size=25):\n",
    "    perm = torch.randperm(dataset.size()[0])\n",
    "    full_dataset = dataset[perm]\n",
    "    full_labels = labels[perm]\n",
    "    test_dataset = full_dataset[-test_size:]\n",
    "    test_labels = full_labels[-test_size:]\n",
    "    train_dataset = full_dataset[:-test_size]\n",
    "    train_labels = full_labels[:-test_size]\n",
    "    return train_dataset,train_labels,test_dataset,test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7e4663b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_model_dataset_preparation(dataset,model,tokenizer,max_length):\n",
    "    model_output = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for sent in dataset:\n",
    "            tokenized_sentence = tokenizer(sent,padding='max_length',max_length=max_length,truncation=True,return_tensors='pt')\n",
    "            model_sent = model(**tokenized_sentence.to('cuda'))\n",
    "            model_output.append(model_sent[1].detach().cpu().numpy())\n",
    "            del model_sent\n",
    "            del tokenized_sentence\n",
    "    model_output = torch.from_numpy(np.array(model_output))\n",
    "    return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8a34fc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_preprocessing(dataset,column):\n",
    "    labels = pd.get_dummies(dataset[column])\n",
    "    dummies_names = []\n",
    "    for i in labels.columns:\n",
    "        dummies_names.append(str(column+'_'+str(i)))\n",
    "    labels = labels.to_numpy()\n",
    "    labels = torch.from_numpy(labels)\n",
    "    return labels, dummies_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fe9f37ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dataset = dataset['original_text'].tolist()\n",
    "labels = dataset.iloc[:,6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7205d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "roberta_tokenizer, roberta_model = init_roberta_model(gpu_usage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e574c3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_processed_text = transformer_model_dataset_preparation(text_dataset,roberta_model,roberta_tokenizer,max_length=380)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "399b56e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8e47abc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itertools.chain(*[[1,2,3],[4,5,6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "084cdb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = labels.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "134c4c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_dimension = columns[:5]\n",
    "syntactic_propertie = columns[6:11]\n",
    "others = columns[11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "776cec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_label_specific_tensors(labels,columns):\n",
    "    dummies = []\n",
    "    container_tensor, dummies_names = labels_preprocessing(labels,columns[0])\n",
    "    dummies.append(dummies_names)\n",
    "    for i in columns[1:]:\n",
    "        labels_tensor,dummies_names = labels_preprocessing(labels,i)\n",
    "        dummies.append(dummies_names) \n",
    "        container_tensor = torch.cat((container_tensor,labels_tensor),dim=-1)\n",
    "    dummies = list(itertools.chain(*dummies))\n",
    "    return container_tensor,dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "63c774aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification_Model(\n",
       "  (ff): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (out): Linear(in_features=768, out_features=12, bias=True)\n",
       "  (selu): SELU()\n",
       ")"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_dimension_labels, dummies = prepare_label_specific_tensors(labels,lexical_dimension)\n",
    "train_dataset,train_labels,test_dataset,test_labels = train_test_split(roberta_processed_text,lexical_dimension_labels,test_size=25)\n",
    "class_model = Classification_Model(input_dim = 768,hidden_size=768,num_classes = lexical_dimension_labels.shape[1])\n",
    "class_model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "373a972e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss value:0.3402113715807597\n",
      "Test Results Epoch 0:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "colloquial_language_0       1.00      0.96      0.98        25\n",
      "colloquial_language_1       0.00      0.00      0.00         0\n",
      "    formal_language_0       1.00      0.96      0.98        25\n",
      "    formal_language_1       0.00      0.00      0.00         0\n",
      " unnecessary_jargon_0       1.00      0.96      0.98        25\n",
      " unnecessary_jargon_1       0.00      0.00      0.00         0\n",
      " unnecessary_jargon_2       0.00      0.00      0.00         0\n",
      "          verbosity_0       1.00      1.00      1.00        25\n",
      "          verbosity_1       0.00      0.00      0.00         0\n",
      "     opaque_writing_0       1.00      0.60      0.75        25\n",
      "     opaque_writing_1       0.00      0.00      0.00         0\n",
      "     opaque_writing_2       0.00      0.00      0.00         0\n",
      "\n",
      "            micro avg       0.90      0.90      0.90       125\n",
      "            macro avg       0.42      0.37      0.39       125\n",
      "         weighted avg       1.00      0.90      0.94       125\n",
      "          samples avg       0.90      0.90      0.90       125\n",
      "\n",
      "Loss value:0.22503932317097983\n",
      "Test Results Epoch 1:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "colloquial_language_0       1.00      0.96      0.98        25\n",
      "colloquial_language_1       0.00      0.00      0.00         0\n",
      "    formal_language_0       1.00      0.96      0.98        25\n",
      "    formal_language_1       0.00      0.00      0.00         0\n",
      " unnecessary_jargon_0       1.00      0.96      0.98        25\n",
      " unnecessary_jargon_1       0.00      0.00      0.00         0\n",
      " unnecessary_jargon_2       0.00      0.00      0.00         0\n",
      "          verbosity_0       1.00      1.00      1.00        25\n",
      "          verbosity_1       0.00      0.00      0.00         0\n",
      "     opaque_writing_0       1.00      0.60      0.75        25\n",
      "     opaque_writing_1       0.00      0.00      0.00         0\n",
      "     opaque_writing_2       0.00      0.00      0.00         0\n",
      "\n",
      "            micro avg       0.90      0.90      0.90       125\n",
      "            macro avg       0.42      0.37      0.39       125\n",
      "         weighted avg       1.00      0.90      0.94       125\n",
      "          samples avg       0.90      0.90      0.90       125\n",
      "\n",
      "Loss value:0.1918611377477646\n",
      "Test Results Epoch 2:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "colloquial_language_0       1.00      0.96      0.98        25\n",
      "colloquial_language_1       0.00      0.00      0.00         0\n",
      "    formal_language_0       1.00      0.96      0.98        25\n",
      "    formal_language_1       0.00      0.00      0.00         0\n",
      " unnecessary_jargon_0       1.00      0.96      0.98        25\n",
      " unnecessary_jargon_1       0.00      0.00      0.00         0\n",
      " unnecessary_jargon_2       0.00      0.00      0.00         0\n",
      "          verbosity_0       1.00      1.00      1.00        25\n",
      "          verbosity_1       0.00      0.00      0.00         0\n",
      "     opaque_writing_0       1.00      0.60      0.75        25\n",
      "     opaque_writing_1       0.00      0.00      0.00         0\n",
      "     opaque_writing_2       0.00      0.00      0.00         0\n",
      "\n",
      "            micro avg       0.90      0.90      0.90       125\n",
      "            macro avg       0.42      0.37      0.39       125\n",
      "         weighted avg       1.00      0.90      0.94       125\n",
      "          samples avg       0.90      0.90      0.90       125\n",
      "\n",
      "Loss value:0.18759276469548544\n",
      "Test Results Epoch 3:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "colloquial_language_0       1.00      0.96      0.98        25\n",
      "colloquial_language_1       0.00      0.00      0.00         0\n",
      "    formal_language_0       1.00      0.96      0.98        25\n",
      "    formal_language_1       0.00      0.00      0.00         0\n",
      " unnecessary_jargon_0       1.00      0.96      0.98        25\n",
      " unnecessary_jargon_1       0.00      0.00      0.00         0\n",
      " unnecessary_jargon_2       0.00      0.00      0.00         0\n",
      "          verbosity_0       1.00      1.00      1.00        25\n",
      "          verbosity_1       0.00      0.00      0.00         0\n",
      "     opaque_writing_0       1.00      0.60      0.75        25\n",
      "     opaque_writing_1       0.00      0.00      0.00         0\n",
      "     opaque_writing_2       0.00      0.00      0.00         0\n",
      "\n",
      "            micro avg       0.90      0.90      0.90       125\n",
      "            macro avg       0.42      0.37      0.39       125\n",
      "         weighted avg       1.00      0.90      0.94       125\n",
      "          samples avg       0.90      0.90      0.90       125\n",
      "\n",
      "Loss value:0.18842262029647827\n",
      "Test Results Epoch 4:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "colloquial_language_0       1.00      0.96      0.98        25\n",
      "colloquial_language_1       0.00      0.00      0.00         0\n",
      "    formal_language_0       1.00      0.96      0.98        25\n",
      "    formal_language_1       0.00      0.00      0.00         0\n",
      " unnecessary_jargon_0       1.00      0.96      0.98        25\n",
      " unnecessary_jargon_1       0.00      0.00      0.00         0\n",
      " unnecessary_jargon_2       0.00      0.00      0.00         0\n",
      "          verbosity_0       1.00      1.00      1.00        25\n",
      "          verbosity_1       0.00      0.00      0.00         0\n",
      "     opaque_writing_0       1.00      0.60      0.75        25\n",
      "     opaque_writing_1       0.00      0.00      0.00         0\n",
      "     opaque_writing_2       0.00      0.00      0.00         0\n",
      "\n",
      "            micro avg       0.90      0.90      0.90       125\n",
      "            macro avg       0.42      0.37      0.39       125\n",
      "         weighted avg       1.00      0.90      0.94       125\n",
      "          samples avg       0.90      0.90      0.90       125\n",
      "\n",
      "Loss value:0.18752064307530722\n",
      "Test Results Epoch 5:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "colloquial_language_0       1.00      0.96      0.98        25\n",
      "colloquial_language_1       0.00      0.00      0.00         0\n",
      "    formal_language_0       1.00      0.96      0.98        25\n",
      "    formal_language_1       0.00      0.00      0.00         0\n",
      " unnecessary_jargon_0       1.00      0.96      0.98        25\n",
      " unnecessary_jargon_1       0.00      0.00      0.00         0\n",
      " unnecessary_jargon_2       0.00      0.00      0.00         0\n",
      "          verbosity_0       1.00      1.00      1.00        25\n",
      "          verbosity_1       0.00      0.00      0.00         0\n",
      "     opaque_writing_0       1.00      0.60      0.75        25\n",
      "     opaque_writing_1       0.00      0.00      0.00         0\n",
      "     opaque_writing_2       0.00      0.00      0.00         0\n",
      "\n",
      "            micro avg       0.90      0.90      0.90       125\n",
      "            macro avg       0.42      0.37      0.39       125\n",
      "         weighted avg       1.00      0.90      0.94       125\n",
      "          samples avg       0.90      0.90      0.90       125\n",
      "\n",
      "Loss value:0.18530629575252533\n",
      "Test Results Epoch 6:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "colloquial_language_0       1.00      0.96      0.98        25\n",
      "colloquial_language_1       0.00      0.00      0.00         0\n",
      "    formal_language_0       1.00      0.96      0.98        25\n",
      "    formal_language_1       0.00      0.00      0.00         0\n",
      " unnecessary_jargon_0       1.00      0.96      0.98        25\n",
      " unnecessary_jargon_1       0.00      0.00      0.00         0\n",
      " unnecessary_jargon_2       0.00      0.00      0.00         0\n",
      "          verbosity_0       1.00      1.00      1.00        25\n",
      "          verbosity_1       0.00      0.00      0.00         0\n",
      "     opaque_writing_0       1.00      0.60      0.75        25\n",
      "     opaque_writing_1       0.00      0.00      0.00         0\n",
      "     opaque_writing_2       0.00      0.00      0.00         0\n",
      "\n",
      "            micro avg       0.90      0.90      0.90       125\n",
      "            macro avg       0.42      0.37      0.39       125\n",
      "         weighted avg       1.00      0.90      0.94       125\n",
      "          samples avg       0.90      0.90      0.90       125\n",
      "\n",
      "Loss value:0.18314741055170694\n",
      "Test Results Epoch 7:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "colloquial_language_0       1.00      0.96      0.98        25\n",
      "colloquial_language_1       0.00      0.00      0.00         0\n",
      "    formal_language_0       1.00      0.96      0.98        25\n",
      "    formal_language_1       0.00      0.00      0.00         0\n",
      " unnecessary_jargon_0       1.00      0.96      0.98        25\n",
      " unnecessary_jargon_1       0.00      0.00      0.00         0\n",
      " unnecessary_jargon_2       0.00      0.00      0.00         0\n",
      "          verbosity_0       1.00      1.00      1.00        25\n",
      "          verbosity_1       0.00      0.00      0.00         0\n",
      "     opaque_writing_0       1.00      0.60      0.75        25\n",
      "     opaque_writing_1       0.00      0.00      0.00         0\n",
      "     opaque_writing_2       0.00      0.00      0.00         0\n",
      "\n",
      "            micro avg       0.90      0.90      0.90       125\n",
      "            macro avg       0.42      0.37      0.39       125\n",
      "         weighted avg       1.00      0.90      0.94       125\n",
      "          samples avg       0.90      0.90      0.90       125\n",
      "\n",
      "Loss value:0.18204646309216818\n",
      "Test Results Epoch 8:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "colloquial_language_0       1.00      0.96      0.98        25\n",
      "colloquial_language_1       0.00      0.00      0.00         0\n",
      "    formal_language_0       1.00      0.96      0.98        25\n",
      "    formal_language_1       0.00      0.00      0.00         0\n",
      " unnecessary_jargon_0       1.00      0.96      0.98        25\n",
      " unnecessary_jargon_1       0.00      0.00      0.00         0\n",
      " unnecessary_jargon_2       0.00      0.00      0.00         0\n",
      "          verbosity_0       1.00      1.00      1.00        25\n",
      "          verbosity_1       0.00      0.00      0.00         0\n",
      "     opaque_writing_0       1.00      0.60      0.75        25\n",
      "     opaque_writing_1       0.00      0.00      0.00         0\n",
      "     opaque_writing_2       0.00      0.00      0.00         0\n",
      "\n",
      "            micro avg       0.90      0.90      0.90       125\n",
      "            macro avg       0.42      0.37      0.39       125\n",
      "         weighted avg       1.00      0.90      0.94       125\n",
      "          samples avg       0.90      0.90      0.90       125\n",
      "\n",
      "Loss value:0.18132378160953522\n",
      "Test Results Epoch 9:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "colloquial_language_0       1.00      0.96      0.98        25\n",
      "colloquial_language_1       0.00      0.00      0.00         0\n",
      "    formal_language_0       1.00      0.96      0.98        25\n",
      "    formal_language_1       0.00      0.00      0.00         0\n",
      " unnecessary_jargon_0       1.00      0.96      0.98        25\n",
      " unnecessary_jargon_1       0.00      0.00      0.00         0\n",
      " unnecessary_jargon_2       0.00      0.00      0.00         0\n",
      "          verbosity_0       1.00      1.00      1.00        25\n",
      "          verbosity_1       0.00      0.00      0.00         0\n",
      "     opaque_writing_0       1.00      0.60      0.75        25\n",
      "     opaque_writing_1       0.00      0.00      0.00         0\n",
      "     opaque_writing_2       0.00      0.00      0.00         0\n",
      "\n",
      "            micro avg       0.90      0.90      0.90       125\n",
      "            macro avg       0.42      0.37      0.39       125\n",
      "         weighted avg       1.00      0.90      0.94       125\n",
      "          samples avg       0.90      0.90      0.90       125\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "batch_size = 25\n",
    "n_batches = math.ceil(len(train_dataset) // batch_size)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(class_model.parameters(),lr=0.0004)\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    batch_losses = []\n",
    "    for i in range(n_batches):\n",
    "        class_model.train()\n",
    "        optimizer.zero_grad()\n",
    "        local_X, local_y = train_dataset[max(0,i * batch_size):min(len(train_dataset),(i+1) * batch_size)] , train_labels[max(0,i * batch_size):min(len(train_labels),(i+1) * batch_size)]\n",
    "        output = class_model(local_X.float().cuda(),batch_size)\n",
    "        loss = criterion(output,local_y.cuda().float())\n",
    "        batch_losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "    print('Loss value:'+str(sum(batch_losses)/len(batch_losses)))\n",
    "    class_model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_out = class_model(test_dataset.float().cuda(),len(test_dataset))\n",
    "        print('Test Results Epoch '+str(epoch)+':')\n",
    "        print(metrics.classification_report(test_out.detach().cpu().numpy()>0.5,test_labels.numpy(),target_names=dummies))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "afad3bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification_Model(\n",
       "  (ff): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (out): Linear(in_features=768, out_features=12, bias=True)\n",
       "  (selu): SELU()\n",
       ")"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntactic_propertie_labels, dummies = prepare_label_specific_tensors(labels,syntactic_propertie)\n",
    "train_dataset,train_labels,test_dataset,test_labels = train_test_split(roberta_processed_text,syntactic_propertie_labels,test_size=25)\n",
    "class_model = Classification_Model(input_dim = 768,hidden_size=768,num_classes = syntactic_propertie_labels.shape[1])\n",
    "class_model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "973a42bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss value:0.5973155299822489\n",
      "Test Results Epoch 0:\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "excessively_complex_syntax_0       1.00      1.00      1.00        25\n",
      "excessively_complex_syntax_1       0.00      0.00      0.00         0\n",
      "excessively_complex_syntax_2       0.00      0.00      0.00         0\n",
      "abuse_of_passive_sentences_0       1.00      1.00      1.00        25\n",
      "abuse_of_passive_sentences_1       0.00      0.00      0.00         0\n",
      "           clear_structure_0       0.00      0.00      0.00         0\n",
      "           clear_structure_1       0.00      0.00      0.00         0\n",
      "           clear_structure_2       0.00      0.00      0.00         0\n",
      "           pretentiousness_0       1.00      0.96      0.98        25\n",
      "           pretentiousness_1       0.00      0.00      0.00         0\n",
      "          engaging_writing_0       1.00      0.88      0.94        25\n",
      "          engaging_writing_1       0.00      0.00      0.00         0\n",
      "\n",
      "                   micro avg       0.77      0.96      0.85       100\n",
      "                   macro avg       0.33      0.32      0.33       100\n",
      "                weighted avg       1.00      0.96      0.98       100\n",
      "                 samples avg       0.77      0.96      0.85       100\n",
      "\n",
      "Loss value:0.3913127879301707\n",
      "Test Results Epoch 1:\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "excessively_complex_syntax_0       1.00      1.00      1.00        25\n",
      "excessively_complex_syntax_1       0.00      0.00      0.00         0\n",
      "excessively_complex_syntax_2       0.00      0.00      0.00         0\n",
      "abuse_of_passive_sentences_0       1.00      1.00      1.00        25\n",
      "abuse_of_passive_sentences_1       0.00      0.00      0.00         0\n",
      "           clear_structure_0       0.00      0.00      0.00         0\n",
      "           clear_structure_1       0.00      0.00      0.00         0\n",
      "           clear_structure_2       0.00      0.00      0.00         0\n",
      "           pretentiousness_0       1.00      0.96      0.98        25\n",
      "           pretentiousness_1       0.00      0.00      0.00         0\n",
      "          engaging_writing_0       1.00      0.88      0.94        25\n",
      "          engaging_writing_1       0.00      0.00      0.00         0\n",
      "\n",
      "                   micro avg       0.77      0.96      0.85       100\n",
      "                   macro avg       0.33      0.32      0.33       100\n",
      "                weighted avg       1.00      0.96      0.98       100\n",
      "                 samples avg       0.77      0.96      0.85       100\n",
      "\n",
      "Loss value:0.315889169772466\n",
      "Test Results Epoch 2:\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "excessively_complex_syntax_0       1.00      1.00      1.00        25\n",
      "excessively_complex_syntax_1       0.00      0.00      0.00         0\n",
      "excessively_complex_syntax_2       0.00      0.00      0.00         0\n",
      "abuse_of_passive_sentences_0       1.00      1.00      1.00        25\n",
      "abuse_of_passive_sentences_1       0.00      0.00      0.00         0\n",
      "           clear_structure_0       0.00      0.00      0.00         0\n",
      "           clear_structure_1       0.00      0.00      0.00         0\n",
      "           clear_structure_2       0.00      0.00      0.00         0\n",
      "           pretentiousness_0       1.00      0.96      0.98        25\n",
      "           pretentiousness_1       0.00      0.00      0.00         0\n",
      "          engaging_writing_0       1.00      0.88      0.94        25\n",
      "          engaging_writing_1       0.00      0.00      0.00         0\n",
      "\n",
      "                   micro avg       0.77      0.96      0.85       100\n",
      "                   macro avg       0.33      0.32      0.33       100\n",
      "                weighted avg       1.00      0.96      0.98       100\n",
      "                 samples avg       0.77      0.96      0.85       100\n",
      "\n",
      "Loss value:0.30533523360888165\n",
      "Test Results Epoch 3:\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "excessively_complex_syntax_0       1.00      1.00      1.00        25\n",
      "excessively_complex_syntax_1       0.00      0.00      0.00         0\n",
      "excessively_complex_syntax_2       0.00      0.00      0.00         0\n",
      "abuse_of_passive_sentences_0       1.00      1.00      1.00        25\n",
      "abuse_of_passive_sentences_1       0.00      0.00      0.00         0\n",
      "           clear_structure_0       0.00      0.00      0.00         0\n",
      "           clear_structure_1       0.00      0.00      0.00         0\n",
      "           clear_structure_2       0.00      0.00      0.00         0\n",
      "           pretentiousness_0       1.00      0.96      0.98        25\n",
      "           pretentiousness_1       0.00      0.00      0.00         0\n",
      "          engaging_writing_0       1.00      0.88      0.94        25\n",
      "          engaging_writing_1       0.00      0.00      0.00         0\n",
      "\n",
      "                   micro avg       0.77      0.96      0.85       100\n",
      "                   macro avg       0.33      0.32      0.33       100\n",
      "                weighted avg       1.00      0.96      0.98       100\n",
      "                 samples avg       0.77      0.96      0.85       100\n",
      "\n",
      "Loss value:0.31130822499593097\n",
      "Test Results Epoch 4:\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "excessively_complex_syntax_0       1.00      1.00      1.00        25\n",
      "excessively_complex_syntax_1       0.00      0.00      0.00         0\n",
      "excessively_complex_syntax_2       0.00      0.00      0.00         0\n",
      "abuse_of_passive_sentences_0       1.00      1.00      1.00        25\n",
      "abuse_of_passive_sentences_1       0.00      0.00      0.00         0\n",
      "           clear_structure_0       0.00      0.00      0.00         0\n",
      "           clear_structure_1       0.00      0.00      0.00         0\n",
      "           clear_structure_2       0.00      0.00      0.00         0\n",
      "           pretentiousness_0       1.00      0.96      0.98        25\n",
      "           pretentiousness_1       0.00      0.00      0.00         0\n",
      "          engaging_writing_0       1.00      0.88      0.94        25\n",
      "          engaging_writing_1       0.00      0.00      0.00         0\n",
      "\n",
      "                   micro avg       0.77      0.96      0.85       100\n",
      "                   macro avg       0.33      0.32      0.33       100\n",
      "                weighted avg       1.00      0.96      0.98       100\n",
      "                 samples avg       0.77      0.96      0.85       100\n",
      "\n",
      "Loss value:0.3144688258568446\n",
      "Test Results Epoch 5:\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "excessively_complex_syntax_0       1.00      1.00      1.00        25\n",
      "excessively_complex_syntax_1       0.00      0.00      0.00         0\n",
      "excessively_complex_syntax_2       0.00      0.00      0.00         0\n",
      "abuse_of_passive_sentences_0       1.00      1.00      1.00        25\n",
      "abuse_of_passive_sentences_1       0.00      0.00      0.00         0\n",
      "           clear_structure_0       0.00      0.00      0.00         0\n",
      "           clear_structure_1       0.00      0.00      0.00         0\n",
      "           clear_structure_2       0.00      0.00      0.00         0\n",
      "           pretentiousness_0       1.00      0.96      0.98        25\n",
      "           pretentiousness_1       0.00      0.00      0.00         0\n",
      "          engaging_writing_0       1.00      0.88      0.94        25\n",
      "          engaging_writing_1       0.00      0.00      0.00         0\n",
      "\n",
      "                   micro avg       0.77      0.96      0.85       100\n",
      "                   macro avg       0.33      0.32      0.33       100\n",
      "                weighted avg       1.00      0.96      0.98       100\n",
      "                 samples avg       0.77      0.96      0.85       100\n",
      "\n",
      "Loss value:0.3125499188899994\n",
      "Test Results Epoch 6:\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "excessively_complex_syntax_0       1.00      1.00      1.00        25\n",
      "excessively_complex_syntax_1       0.00      0.00      0.00         0\n",
      "excessively_complex_syntax_2       0.00      0.00      0.00         0\n",
      "abuse_of_passive_sentences_0       1.00      1.00      1.00        25\n",
      "abuse_of_passive_sentences_1       0.00      0.00      0.00         0\n",
      "           clear_structure_0       0.00      0.00      0.00         0\n",
      "           clear_structure_1       0.00      0.00      0.00         0\n",
      "           clear_structure_2       0.00      0.00      0.00         0\n",
      "           pretentiousness_0       1.00      0.96      0.98        25\n",
      "           pretentiousness_1       0.00      0.00      0.00         0\n",
      "          engaging_writing_0       1.00      0.88      0.94        25\n",
      "          engaging_writing_1       0.00      0.00      0.00         0\n",
      "\n",
      "                   micro avg       0.77      0.96      0.85       100\n",
      "                   macro avg       0.33      0.32      0.33       100\n",
      "                weighted avg       1.00      0.96      0.98       100\n",
      "                 samples avg       0.77      0.96      0.85       100\n",
      "\n",
      "Loss value:0.309081236521403\n",
      "Test Results Epoch 7:\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "excessively_complex_syntax_0       1.00      1.00      1.00        25\n",
      "excessively_complex_syntax_1       0.00      0.00      0.00         0\n",
      "excessively_complex_syntax_2       0.00      0.00      0.00         0\n",
      "abuse_of_passive_sentences_0       1.00      1.00      1.00        25\n",
      "abuse_of_passive_sentences_1       0.00      0.00      0.00         0\n",
      "           clear_structure_0       0.00      0.00      0.00         0\n",
      "           clear_structure_1       0.00      0.00      0.00         0\n",
      "           clear_structure_2       0.00      0.00      0.00         0\n",
      "           pretentiousness_0       1.00      0.96      0.98        25\n",
      "           pretentiousness_1       0.00      0.00      0.00         0\n",
      "          engaging_writing_0       1.00      0.88      0.94        25\n",
      "          engaging_writing_1       0.00      0.00      0.00         0\n",
      "\n",
      "                   micro avg       0.77      0.96      0.85       100\n",
      "                   macro avg       0.33      0.32      0.33       100\n",
      "                weighted avg       1.00      0.96      0.98       100\n",
      "                 samples avg       0.77      0.96      0.85       100\n",
      "\n",
      "Loss value:0.30653539299964905\n",
      "Test Results Epoch 8:\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "excessively_complex_syntax_0       1.00      1.00      1.00        25\n",
      "excessively_complex_syntax_1       0.00      0.00      0.00         0\n",
      "excessively_complex_syntax_2       0.00      0.00      0.00         0\n",
      "abuse_of_passive_sentences_0       1.00      1.00      1.00        25\n",
      "abuse_of_passive_sentences_1       0.00      0.00      0.00         0\n",
      "           clear_structure_0       0.00      0.00      0.00         0\n",
      "           clear_structure_1       0.00      0.00      0.00         0\n",
      "           clear_structure_2       0.00      0.00      0.00         0\n",
      "           pretentiousness_0       1.00      0.96      0.98        25\n",
      "           pretentiousness_1       0.00      0.00      0.00         0\n",
      "          engaging_writing_0       1.00      0.88      0.94        25\n",
      "          engaging_writing_1       0.00      0.00      0.00         0\n",
      "\n",
      "                   micro avg       0.77      0.96      0.85       100\n",
      "                   macro avg       0.33      0.32      0.33       100\n",
      "                weighted avg       1.00      0.96      0.98       100\n",
      "                 samples avg       0.77      0.96      0.85       100\n",
      "\n",
      "Loss value:0.3050083915392558\n",
      "Test Results Epoch 9:\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "excessively_complex_syntax_0       1.00      1.00      1.00        25\n",
      "excessively_complex_syntax_1       0.00      0.00      0.00         0\n",
      "excessively_complex_syntax_2       0.00      0.00      0.00         0\n",
      "abuse_of_passive_sentences_0       1.00      1.00      1.00        25\n",
      "abuse_of_passive_sentences_1       0.00      0.00      0.00         0\n",
      "           clear_structure_0       0.00      0.00      0.00         0\n",
      "           clear_structure_1       0.00      0.00      0.00         0\n",
      "           clear_structure_2       0.00      0.00      0.00         0\n",
      "           pretentiousness_0       1.00      0.96      0.98        25\n",
      "           pretentiousness_1       0.00      0.00      0.00         0\n",
      "          engaging_writing_0       1.00      0.88      0.94        25\n",
      "          engaging_writing_1       0.00      0.00      0.00         0\n",
      "\n",
      "                   micro avg       0.77      0.96      0.85       100\n",
      "                   macro avg       0.33      0.32      0.33       100\n",
      "                weighted avg       1.00      0.96      0.98       100\n",
      "                 samples avg       0.77      0.96      0.85       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "batch_size = 25\n",
    "n_batches = math.ceil(len(train_dataset) // batch_size)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(class_model.parameters(),lr=0.0004)\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    batch_losses = []\n",
    "    for i in range(n_batches):\n",
    "        class_model.train()\n",
    "        optimizer.zero_grad()\n",
    "        local_X, local_y = train_dataset[max(0,i * batch_size):min(len(train_dataset),(i+1) * batch_size)] , train_labels[max(0,i * batch_size):min(len(train_labels),(i+1) * batch_size)]\n",
    "        output = class_model(local_X.float().cuda(),batch_size)\n",
    "        loss = criterion(output,local_y.cuda().float())\n",
    "        batch_losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "    print('Loss value:'+str(sum(batch_losses)/len(batch_losses)))\n",
    "    class_model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_out = class_model(test_dataset.float().cuda(),len(test_dataset))\n",
    "        print('Test Results Epoch '+str(epoch)+':')\n",
    "        print(metrics.classification_report(test_out.detach().cpu().numpy()>0.5,test_labels.numpy(),target_names=dummies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a82a60eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification_Model(\n",
       "  (ff): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (out): Linear(in_features=768, out_features=27, bias=True)\n",
       "  (selu): SELU()\n",
       ")"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "others_labels, dummies = prepare_label_specific_tensors(labels,others)\n",
    "train_dataset,train_labels,test_dataset,test_labels = train_test_split(roberta_processed_text,others_labels,test_size=25)\n",
    "class_model = Classification_Model(input_dim = 768,hidden_size=768,num_classes = others_labels.shape[1])\n",
    "class_model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "12da19e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss value:0.6132851839065552\n",
      "Test Results Epoch 0:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dull_writing_0       1.00      0.80      0.89        25\n",
      "dull_writing_1       0.00      0.00      0.00         0\n",
      "dull_writing_2       0.00      0.00      0.00         0\n",
      "     unclear_0       0.00      0.00      0.00         0\n",
      "     unclear_1       0.00      0.00      0.00         0\n",
      "     unclear_2       0.00      0.00      0.00         0\n",
      "     unclear_3       0.00      0.00      0.00         0\n",
      " word_choice_0       0.06      1.00      0.12         1\n",
      " word_choice_1       0.00      0.00      0.00         0\n",
      " word_choice_2       0.00      0.00      0.00         0\n",
      " word_choice_3       0.00      0.00      0.00         0\n",
      "  repetition_0       1.00      0.96      0.98        25\n",
      "  repetition_1       0.00      0.00      0.00         0\n",
      "  repetition_2       0.00      0.00      0.00         0\n",
      "    fragment_0       1.00      0.80      0.89        25\n",
      "    fragment_1       0.00      0.00      0.00         0\n",
      "    fragment_2       0.00      0.00      0.00         0\n",
      "non_sequitor_0       1.00      0.92      0.96        25\n",
      "non_sequitor_1       0.00      0.00      0.00         0\n",
      "non_sequitor_2       0.00      0.00      0.00         0\n",
      "non_sequitor_3       0.00      0.00      0.00         0\n",
      "   poor_flow_0       1.00      0.88      0.94        25\n",
      "   poor_flow_1       0.00      0.00      0.00         0\n",
      "   poor_flow_2       0.00      0.00      0.00         0\n",
      "   redundant_0       1.00      0.88      0.94        25\n",
      "   redundant_1       0.00      0.00      0.00         0\n",
      "   redundant_2       0.00      0.00      0.00         0\n",
      "\n",
      "     micro avg       0.66      0.87      0.75       151\n",
      "     macro avg       0.22      0.23      0.21       151\n",
      "  weighted avg       0.99      0.87      0.93       151\n",
      "   samples avg       0.66      0.87      0.75       151\n",
      "\n",
      "Loss value:0.41735663016637164\n",
      "Test Results Epoch 1:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dull_writing_0       1.00      0.80      0.89        25\n",
      "dull_writing_1       0.00      0.00      0.00         0\n",
      "dull_writing_2       0.00      0.00      0.00         0\n",
      "     unclear_0       1.00      0.68      0.81        25\n",
      "     unclear_1       0.00      0.00      0.00         0\n",
      "     unclear_2       0.00      0.00      0.00         0\n",
      "     unclear_3       0.00      0.00      0.00         0\n",
      " word_choice_0       1.00      0.64      0.78        25\n",
      " word_choice_1       0.00      0.00      0.00         0\n",
      " word_choice_2       0.00      0.00      0.00         0\n",
      " word_choice_3       0.00      0.00      0.00         0\n",
      "  repetition_0       1.00      0.96      0.98        25\n",
      "  repetition_1       0.00      0.00      0.00         0\n",
      "  repetition_2       0.00      0.00      0.00         0\n",
      "    fragment_0       1.00      0.80      0.89        25\n",
      "    fragment_1       0.00      0.00      0.00         0\n",
      "    fragment_2       0.00      0.00      0.00         0\n",
      "non_sequitor_0       1.00      0.92      0.96        25\n",
      "non_sequitor_1       0.00      0.00      0.00         0\n",
      "non_sequitor_2       0.00      0.00      0.00         0\n",
      "non_sequitor_3       0.00      0.00      0.00         0\n",
      "   poor_flow_0       1.00      0.88      0.94        25\n",
      "   poor_flow_1       0.00      0.00      0.00         0\n",
      "   poor_flow_2       0.00      0.00      0.00         0\n",
      "   redundant_0       1.00      0.88      0.94        25\n",
      "   redundant_1       0.00      0.00      0.00         0\n",
      "   redundant_2       0.00      0.00      0.00         0\n",
      "\n",
      "     micro avg       0.82      0.82      0.82       200\n",
      "     macro avg       0.30      0.24      0.27       200\n",
      "  weighted avg       1.00      0.82      0.90       200\n",
      "   samples avg       0.82      0.82      0.82       200\n",
      "\n",
      "Loss value:0.2976326247056325\n",
      "Test Results Epoch 2:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dull_writing_0       1.00      0.80      0.89        25\n",
      "dull_writing_1       0.00      0.00      0.00         0\n",
      "dull_writing_2       0.00      0.00      0.00         0\n",
      "     unclear_0       1.00      0.68      0.81        25\n",
      "     unclear_1       0.00      0.00      0.00         0\n",
      "     unclear_2       0.00      0.00      0.00         0\n",
      "     unclear_3       0.00      0.00      0.00         0\n",
      " word_choice_0       1.00      0.64      0.78        25\n",
      " word_choice_1       0.00      0.00      0.00         0\n",
      " word_choice_2       0.00      0.00      0.00         0\n",
      " word_choice_3       0.00      0.00      0.00         0\n",
      "  repetition_0       1.00      0.96      0.98        25\n",
      "  repetition_1       0.00      0.00      0.00         0\n",
      "  repetition_2       0.00      0.00      0.00         0\n",
      "    fragment_0       1.00      0.80      0.89        25\n",
      "    fragment_1       0.00      0.00      0.00         0\n",
      "    fragment_2       0.00      0.00      0.00         0\n",
      "non_sequitor_0       1.00      0.92      0.96        25\n",
      "non_sequitor_1       0.00      0.00      0.00         0\n",
      "non_sequitor_2       0.00      0.00      0.00         0\n",
      "non_sequitor_3       0.00      0.00      0.00         0\n",
      "   poor_flow_0       1.00      0.88      0.94        25\n",
      "   poor_flow_1       0.00      0.00      0.00         0\n",
      "   poor_flow_2       0.00      0.00      0.00         0\n",
      "   redundant_0       1.00      0.88      0.94        25\n",
      "   redundant_1       0.00      0.00      0.00         0\n",
      "   redundant_2       0.00      0.00      0.00         0\n",
      "\n",
      "     micro avg       0.82      0.82      0.82       200\n",
      "     macro avg       0.30      0.24      0.27       200\n",
      "  weighted avg       1.00      0.82      0.90       200\n",
      "   samples avg       0.82      0.82      0.82       200\n",
      "\n",
      "Loss value:0.25204501549402875\n",
      "Test Results Epoch 3:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dull_writing_0       1.00      0.80      0.89        25\n",
      "dull_writing_1       0.00      0.00      0.00         0\n",
      "dull_writing_2       0.00      0.00      0.00         0\n",
      "     unclear_0       1.00      0.68      0.81        25\n",
      "     unclear_1       0.00      0.00      0.00         0\n",
      "     unclear_2       0.00      0.00      0.00         0\n",
      "     unclear_3       0.00      0.00      0.00         0\n",
      " word_choice_0       1.00      0.64      0.78        25\n",
      " word_choice_1       0.00      0.00      0.00         0\n",
      " word_choice_2       0.00      0.00      0.00         0\n",
      " word_choice_3       0.00      0.00      0.00         0\n",
      "  repetition_0       1.00      0.96      0.98        25\n",
      "  repetition_1       0.00      0.00      0.00         0\n",
      "  repetition_2       0.00      0.00      0.00         0\n",
      "    fragment_0       1.00      0.80      0.89        25\n",
      "    fragment_1       0.00      0.00      0.00         0\n",
      "    fragment_2       0.00      0.00      0.00         0\n",
      "non_sequitor_0       1.00      0.92      0.96        25\n",
      "non_sequitor_1       0.00      0.00      0.00         0\n",
      "non_sequitor_2       0.00      0.00      0.00         0\n",
      "non_sequitor_3       0.00      0.00      0.00         0\n",
      "   poor_flow_0       1.00      0.88      0.94        25\n",
      "   poor_flow_1       0.00      0.00      0.00         0\n",
      "   poor_flow_2       0.00      0.00      0.00         0\n",
      "   redundant_0       1.00      0.88      0.94        25\n",
      "   redundant_1       0.00      0.00      0.00         0\n",
      "   redundant_2       0.00      0.00      0.00         0\n",
      "\n",
      "     micro avg       0.82      0.82      0.82       200\n",
      "     macro avg       0.30      0.24      0.27       200\n",
      "  weighted avg       1.00      0.82      0.90       200\n",
      "   samples avg       0.82      0.82      0.82       200\n",
      "\n",
      "Loss value:0.24683275322119394\n",
      "Test Results Epoch 4:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dull_writing_0       1.00      0.80      0.89        25\n",
      "dull_writing_1       0.00      0.00      0.00         0\n",
      "dull_writing_2       0.00      0.00      0.00         0\n",
      "     unclear_0       1.00      0.68      0.81        25\n",
      "     unclear_1       0.00      0.00      0.00         0\n",
      "     unclear_2       0.00      0.00      0.00         0\n",
      "     unclear_3       0.00      0.00      0.00         0\n",
      " word_choice_0       1.00      0.64      0.78        25\n",
      " word_choice_1       0.00      0.00      0.00         0\n",
      " word_choice_2       0.00      0.00      0.00         0\n",
      " word_choice_3       0.00      0.00      0.00         0\n",
      "  repetition_0       1.00      0.96      0.98        25\n",
      "  repetition_1       0.00      0.00      0.00         0\n",
      "  repetition_2       0.00      0.00      0.00         0\n",
      "    fragment_0       1.00      0.80      0.89        25\n",
      "    fragment_1       0.00      0.00      0.00         0\n",
      "    fragment_2       0.00      0.00      0.00         0\n",
      "non_sequitor_0       1.00      0.92      0.96        25\n",
      "non_sequitor_1       0.00      0.00      0.00         0\n",
      "non_sequitor_2       0.00      0.00      0.00         0\n",
      "non_sequitor_3       0.00      0.00      0.00         0\n",
      "   poor_flow_0       1.00      0.88      0.94        25\n",
      "   poor_flow_1       0.00      0.00      0.00         0\n",
      "   poor_flow_2       0.00      0.00      0.00         0\n",
      "   redundant_0       1.00      0.88      0.94        25\n",
      "   redundant_1       0.00      0.00      0.00         0\n",
      "   redundant_2       0.00      0.00      0.00         0\n",
      "\n",
      "     micro avg       0.82      0.82      0.82       200\n",
      "     macro avg       0.30      0.24      0.27       200\n",
      "  weighted avg       1.00      0.82      0.90       200\n",
      "   samples avg       0.82      0.82      0.82       200\n",
      "\n",
      "Loss value:0.2501746714115143\n",
      "Test Results Epoch 5:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dull_writing_0       1.00      0.80      0.89        25\n",
      "dull_writing_1       0.00      0.00      0.00         0\n",
      "dull_writing_2       0.00      0.00      0.00         0\n",
      "     unclear_0       1.00      0.68      0.81        25\n",
      "     unclear_1       0.00      0.00      0.00         0\n",
      "     unclear_2       0.00      0.00      0.00         0\n",
      "     unclear_3       0.00      0.00      0.00         0\n",
      " word_choice_0       1.00      0.64      0.78        25\n",
      " word_choice_1       0.00      0.00      0.00         0\n",
      " word_choice_2       0.00      0.00      0.00         0\n",
      " word_choice_3       0.00      0.00      0.00         0\n",
      "  repetition_0       1.00      0.96      0.98        25\n",
      "  repetition_1       0.00      0.00      0.00         0\n",
      "  repetition_2       0.00      0.00      0.00         0\n",
      "    fragment_0       1.00      0.80      0.89        25\n",
      "    fragment_1       0.00      0.00      0.00         0\n",
      "    fragment_2       0.00      0.00      0.00         0\n",
      "non_sequitor_0       1.00      0.92      0.96        25\n",
      "non_sequitor_1       0.00      0.00      0.00         0\n",
      "non_sequitor_2       0.00      0.00      0.00         0\n",
      "non_sequitor_3       0.00      0.00      0.00         0\n",
      "   poor_flow_0       1.00      0.88      0.94        25\n",
      "   poor_flow_1       0.00      0.00      0.00         0\n",
      "   poor_flow_2       0.00      0.00      0.00         0\n",
      "   redundant_0       1.00      0.88      0.94        25\n",
      "   redundant_1       0.00      0.00      0.00         0\n",
      "   redundant_2       0.00      0.00      0.00         0\n",
      "\n",
      "     micro avg       0.82      0.82      0.82       200\n",
      "     macro avg       0.30      0.24      0.27       200\n",
      "  weighted avg       1.00      0.82      0.90       200\n",
      "   samples avg       0.82      0.82      0.82       200\n",
      "\n",
      "Loss value:0.2491663545370102\n",
      "Test Results Epoch 6:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dull_writing_0       1.00      0.80      0.89        25\n",
      "dull_writing_1       0.00      0.00      0.00         0\n",
      "dull_writing_2       0.00      0.00      0.00         0\n",
      "     unclear_0       1.00      0.68      0.81        25\n",
      "     unclear_1       0.00      0.00      0.00         0\n",
      "     unclear_2       0.00      0.00      0.00         0\n",
      "     unclear_3       0.00      0.00      0.00         0\n",
      " word_choice_0       1.00      0.64      0.78        25\n",
      " word_choice_1       0.00      0.00      0.00         0\n",
      " word_choice_2       0.00      0.00      0.00         0\n",
      " word_choice_3       0.00      0.00      0.00         0\n",
      "  repetition_0       1.00      0.96      0.98        25\n",
      "  repetition_1       0.00      0.00      0.00         0\n",
      "  repetition_2       0.00      0.00      0.00         0\n",
      "    fragment_0       1.00      0.80      0.89        25\n",
      "    fragment_1       0.00      0.00      0.00         0\n",
      "    fragment_2       0.00      0.00      0.00         0\n",
      "non_sequitor_0       1.00      0.92      0.96        25\n",
      "non_sequitor_1       0.00      0.00      0.00         0\n",
      "non_sequitor_2       0.00      0.00      0.00         0\n",
      "non_sequitor_3       0.00      0.00      0.00         0\n",
      "   poor_flow_0       1.00      0.88      0.94        25\n",
      "   poor_flow_1       0.00      0.00      0.00         0\n",
      "   poor_flow_2       0.00      0.00      0.00         0\n",
      "   redundant_0       1.00      0.88      0.94        25\n",
      "   redundant_1       0.00      0.00      0.00         0\n",
      "   redundant_2       0.00      0.00      0.00         0\n",
      "\n",
      "     micro avg       0.82      0.82      0.82       200\n",
      "     macro avg       0.30      0.24      0.27       200\n",
      "  weighted avg       1.00      0.82      0.90       200\n",
      "   samples avg       0.82      0.82      0.82       200\n",
      "\n",
      "Loss value:0.24478320280710855\n",
      "Test Results Epoch 7:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dull_writing_0       1.00      0.80      0.89        25\n",
      "dull_writing_1       0.00      0.00      0.00         0\n",
      "dull_writing_2       0.00      0.00      0.00         0\n",
      "     unclear_0       1.00      0.68      0.81        25\n",
      "     unclear_1       0.00      0.00      0.00         0\n",
      "     unclear_2       0.00      0.00      0.00         0\n",
      "     unclear_3       0.00      0.00      0.00         0\n",
      " word_choice_0       1.00      0.64      0.78        25\n",
      " word_choice_1       0.00      0.00      0.00         0\n",
      " word_choice_2       0.00      0.00      0.00         0\n",
      " word_choice_3       0.00      0.00      0.00         0\n",
      "  repetition_0       1.00      0.96      0.98        25\n",
      "  repetition_1       0.00      0.00      0.00         0\n",
      "  repetition_2       0.00      0.00      0.00         0\n",
      "    fragment_0       1.00      0.80      0.89        25\n",
      "    fragment_1       0.00      0.00      0.00         0\n",
      "    fragment_2       0.00      0.00      0.00         0\n",
      "non_sequitor_0       1.00      0.92      0.96        25\n",
      "non_sequitor_1       0.00      0.00      0.00         0\n",
      "non_sequitor_2       0.00      0.00      0.00         0\n",
      "non_sequitor_3       0.00      0.00      0.00         0\n",
      "   poor_flow_0       1.00      0.88      0.94        25\n",
      "   poor_flow_1       0.00      0.00      0.00         0\n",
      "   poor_flow_2       0.00      0.00      0.00         0\n",
      "   redundant_0       1.00      0.88      0.94        25\n",
      "   redundant_1       0.00      0.00      0.00         0\n",
      "   redundant_2       0.00      0.00      0.00         0\n",
      "\n",
      "     micro avg       0.82      0.82      0.82       200\n",
      "     macro avg       0.30      0.24      0.27       200\n",
      "  weighted avg       1.00      0.82      0.90       200\n",
      "   samples avg       0.82      0.82      0.82       200\n",
      "\n",
      "Loss value:0.24100554982821146\n",
      "Test Results Epoch 8:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dull_writing_0       1.00      0.80      0.89        25\n",
      "dull_writing_1       0.00      0.00      0.00         0\n",
      "dull_writing_2       0.00      0.00      0.00         0\n",
      "     unclear_0       1.00      0.68      0.81        25\n",
      "     unclear_1       0.00      0.00      0.00         0\n",
      "     unclear_2       0.00      0.00      0.00         0\n",
      "     unclear_3       0.00      0.00      0.00         0\n",
      " word_choice_0       1.00      0.64      0.78        25\n",
      " word_choice_1       0.00      0.00      0.00         0\n",
      " word_choice_2       0.00      0.00      0.00         0\n",
      " word_choice_3       0.00      0.00      0.00         0\n",
      "  repetition_0       1.00      0.96      0.98        25\n",
      "  repetition_1       0.00      0.00      0.00         0\n",
      "  repetition_2       0.00      0.00      0.00         0\n",
      "    fragment_0       1.00      0.80      0.89        25\n",
      "    fragment_1       0.00      0.00      0.00         0\n",
      "    fragment_2       0.00      0.00      0.00         0\n",
      "non_sequitor_0       1.00      0.92      0.96        25\n",
      "non_sequitor_1       0.00      0.00      0.00         0\n",
      "non_sequitor_2       0.00      0.00      0.00         0\n",
      "non_sequitor_3       0.00      0.00      0.00         0\n",
      "   poor_flow_0       1.00      0.88      0.94        25\n",
      "   poor_flow_1       0.00      0.00      0.00         0\n",
      "   poor_flow_2       0.00      0.00      0.00         0\n",
      "   redundant_0       1.00      0.88      0.94        25\n",
      "   redundant_1       0.00      0.00      0.00         0\n",
      "   redundant_2       0.00      0.00      0.00         0\n",
      "\n",
      "     micro avg       0.82      0.82      0.82       200\n",
      "     macro avg       0.30      0.24      0.27       200\n",
      "  weighted avg       1.00      0.82      0.90       200\n",
      "   samples avg       0.82      0.82      0.82       200\n",
      "\n",
      "Loss value:0.23792916536331177\n",
      "Test Results Epoch 9:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "dull_writing_0       1.00      0.80      0.89        25\n",
      "dull_writing_1       0.00      0.00      0.00         0\n",
      "dull_writing_2       0.00      0.00      0.00         0\n",
      "     unclear_0       1.00      0.68      0.81        25\n",
      "     unclear_1       0.00      0.00      0.00         0\n",
      "     unclear_2       0.00      0.00      0.00         0\n",
      "     unclear_3       0.00      0.00      0.00         0\n",
      " word_choice_0       1.00      0.64      0.78        25\n",
      " word_choice_1       0.00      0.00      0.00         0\n",
      " word_choice_2       0.00      0.00      0.00         0\n",
      " word_choice_3       0.00      0.00      0.00         0\n",
      "  repetition_0       1.00      0.96      0.98        25\n",
      "  repetition_1       0.00      0.00      0.00         0\n",
      "  repetition_2       0.00      0.00      0.00         0\n",
      "    fragment_0       1.00      0.80      0.89        25\n",
      "    fragment_1       0.00      0.00      0.00         0\n",
      "    fragment_2       0.00      0.00      0.00         0\n",
      "non_sequitor_0       1.00      0.92      0.96        25\n",
      "non_sequitor_1       0.00      0.00      0.00         0\n",
      "non_sequitor_2       0.00      0.00      0.00         0\n",
      "non_sequitor_3       0.00      0.00      0.00         0\n",
      "   poor_flow_0       1.00      0.88      0.94        25\n",
      "   poor_flow_1       0.00      0.00      0.00         0\n",
      "   poor_flow_2       0.00      0.00      0.00         0\n",
      "   redundant_0       1.00      0.88      0.94        25\n",
      "   redundant_1       0.00      0.00      0.00         0\n",
      "   redundant_2       0.00      0.00      0.00         0\n",
      "\n",
      "     micro avg       0.82      0.82      0.82       200\n",
      "     macro avg       0.30      0.24      0.27       200\n",
      "  weighted avg       1.00      0.82      0.90       200\n",
      "   samples avg       0.82      0.82      0.82       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "batch_size = 25\n",
    "n_batches = math.ceil(len(train_dataset) // batch_size)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(class_model.parameters(),lr=0.0004)\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    batch_losses = []\n",
    "    for i in range(n_batches):\n",
    "        class_model.train()\n",
    "        optimizer.zero_grad()\n",
    "        local_X, local_y = train_dataset[max(0,i * batch_size):min(len(train_dataset),(i+1) * batch_size)] , train_labels[max(0,i * batch_size):min(len(train_labels),(i+1) * batch_size)]\n",
    "        output = class_model(local_X.float().cuda(),batch_size)\n",
    "        loss = criterion(output,local_y.cuda().float())\n",
    "        batch_losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "    print('Loss value:'+str(sum(batch_losses)/len(batch_losses)))\n",
    "    class_model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_out = class_model(test_dataset.float().cuda(),len(test_dataset))\n",
    "        print('Test Results Epoch '+str(epoch)+':')\n",
    "        print(metrics.classification_report(test_out.detach().cpu().numpy()>0.5,test_labels.numpy(),target_names=dummies))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7852d2",
   "metadata": {},
   "source": [
    "## Text Generation\n",
    "In this final section, i am going to training a Seq-2-Seq model to generate text from \"outline-1\" to the original text immitating the improvement of text as my understandment. The model is using RoBERTa as its encoder and 2-layer transformer decoders. The decoders is the normal \"attention is all you need\" decoders with 2 attention heads and 2048 as FFN. I have worked on this text2text generation before and training the model with unfrozen layers achieve much better performance specially for domain specific tasks like this one exactly. Most of the internal parameters chosen are very similar to my experimentations with Machine Translation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "fbd6f992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pad_mask(seq, pad_idx):\n",
    "    return (seq != pad_idx).unsqueeze(-2)\n",
    "\n",
    "\n",
    "def get_subsequent_mask(seq):\n",
    "    sz_b, len_s = seq.size()\n",
    "    subsequent_mask = (1 - torch.triu(\n",
    "        torch.ones((1, len_s, len_s), device=seq.device), diagonal=1)).bool()\n",
    "    return subsequent_mask\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_hid, n_position=200):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.register_buffer('pos_table', self._get_sinusoid_encoding_table(n_position, d_hid))\n",
    "\n",
    "    def _get_sinusoid_encoding_table(self, n_position, d_hid):\n",
    "        def get_position_angle_vec(position):\n",
    "            return [position / np.power(10000, 2 * (hid_j // 2) / d_hid) for hid_j in range(d_hid)]\n",
    "\n",
    "        sinusoid_table = np.array([get_position_angle_vec(pos_i) for pos_i in range(n_position)])\n",
    "        sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n",
    "        sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n",
    "\n",
    "        return torch.FloatTensor(sinusoid_table).unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pos_table[:, :x.size(1)].clone().detach()\n",
    "\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, temperature, attn_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.dropout = nn.Dropout(attn_dropout)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "\n",
    "        attn = torch.matmul(q / self.temperature, k.transpose(2, 3))\n",
    "\n",
    "        if mask is not None:\n",
    "            attn = attn.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        attn = self.dropout(F.softmax(attn, dim=-1))\n",
    "        output = torch.matmul(attn, v)\n",
    "\n",
    "        return output, attn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, n_head, d_model, d_k, d_v, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "\n",
    "        self.w_qs = nn.Linear(d_model, n_head * d_k, bias=False)\n",
    "        self.w_ks = nn.Linear(d_model, n_head * d_k, bias=False)\n",
    "        self.w_vs = nn.Linear(d_model, n_head * d_v, bias=False)\n",
    "        self.fc = nn.Linear(n_head * d_v, d_model, bias=False)\n",
    "\n",
    "        self.attention = ScaledDotProductAttention(temperature=d_k ** 0.5)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "\n",
    "        d_k, d_v, n_head = self.d_k, self.d_v, self.n_head\n",
    "        sz_b, len_q, len_k, len_v = q.size(0), q.size(1), k.size(1), v.size(1)\n",
    "\n",
    "        residual = q\n",
    "\n",
    "\n",
    "        q = self.w_qs(q).view(sz_b, len_q, n_head, d_k)\n",
    "        k = self.w_ks(k).view(sz_b, len_k, n_head, d_k)\n",
    "        v = self.w_vs(v).view(sz_b, len_v, n_head, d_v)\n",
    "\n",
    " \n",
    "        q, k, v = q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)   \n",
    "\n",
    "        q, attn = self.attention(q, k, v, mask=mask)\n",
    "        q = q.transpose(1, 2).contiguous().view(sz_b, len_q, -1)\n",
    "        q = self.dropout(self.fc(q))\n",
    "        q += residual\n",
    "\n",
    "        q = self.layer_norm(q)\n",
    "\n",
    "        return q, attn\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_in, d_hid, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.w_1 = nn.Linear(d_in, d_hid) # position-wise\n",
    "        self.w_2 = nn.Linear(d_hid, d_in) # position-wise\n",
    "        self.layer_norm = nn.LayerNorm(d_in, eps=1e-6)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        residual = x\n",
    "\n",
    "        x = self.w_2(F.relu(self.w_1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x += residual\n",
    "\n",
    "        x = self.layer_norm(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, d_inner, n_head, d_k, d_v, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.slf_attn = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout)\n",
    "        self.enc_attn = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout)\n",
    "        self.pos_ffn = PositionwiseFeedForward(d_model, d_inner, dropout=dropout)\n",
    "\n",
    "    def forward(\n",
    "            self, dec_input, enc_output,\n",
    "            slf_attn_mask=None, dec_enc_attn_mask=None):\n",
    "        dec_output, dec_slf_attn = self.slf_attn(\n",
    "            dec_input, dec_input, dec_input, mask=slf_attn_mask)\n",
    "        dec_output, dec_enc_attn = self.enc_attn(\n",
    "            dec_output, enc_output, enc_output, mask=dec_enc_attn_mask)\n",
    "        dec_output = self.pos_ffn(dec_output)\n",
    "        return dec_output, dec_slf_attn, dec_enc_attn\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "            self, n_trg_vocab, d_word_vec, n_layers, n_head, d_k, d_v,\n",
    "            d_model, d_inner, pad_idx, n_position, dropout=0.1):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.trg_word_emb = nn.Embedding(n_trg_vocab, d_word_vec, padding_idx=pad_idx)\n",
    "        self.position_enc = PositionalEncoding(d_word_vec, n_position=n_position)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.layer_stack = nn.ModuleList([\n",
    "            DecoderLayer(d_model, d_inner, n_head, d_k, d_v, dropout=dropout)\n",
    "            for _ in range(n_layers)])\n",
    "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, trg_seq, trg_mask, enc_output, src_mask, return_attns=False):\n",
    "\n",
    "        dec_slf_attn_list, dec_enc_attn_list = [], []\n",
    "\n",
    "        # -- Forward\n",
    "        dec_output = self.trg_word_emb(trg_seq)\n",
    "        dec_output = self.dropout(self.position_enc(dec_output))\n",
    "        dec_output = self.layer_norm(dec_output)\n",
    "\n",
    "        for dec_layer in self.layer_stack:\n",
    "            dec_output, dec_slf_attn, dec_enc_attn = dec_layer(\n",
    "                dec_output, enc_output, slf_attn_mask=trg_mask, dec_enc_attn_mask=src_mask)\n",
    "            dec_slf_attn_list += [dec_slf_attn] if return_attns else []\n",
    "            dec_enc_attn_list += [dec_enc_attn] if return_attns else []\n",
    "\n",
    "        if return_attns:\n",
    "            return dec_output, dec_slf_attn_list, dec_enc_attn_list\n",
    "        return dec_output,\n",
    "\n",
    "\n",
    "class Modified_Transformer(nn.Module):\n",
    "    def __init__(self,encoder, decoder_vocab, d_model,n_layers, attn_heads, d_ffn, pad_idx, n_positions,dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        for p in self.encoder.parameters():\n",
    "            p.requires_grad = False\n",
    "        dk = d_model // attn_heads\n",
    "        self.decoder = Decoder(n_trg_vocab = decoder_vocab, d_word_vec = d_model, n_layers = n_layers, n_head = attn_heads,\n",
    "                               d_k = dk, d_v = dk, d_model = d_model, d_inner = d_ffn, pad_idx = pad_idx, n_position = n_positions)\n",
    "        \n",
    "        self.decoder.trg_word_emb = self.encoder.embeddings.word_embeddings\n",
    "        self.decoder.trg_word_emb.requires_grad = False\n",
    "        self.trg_pad_idx = pad_idx \n",
    "        self.trg_word_prj = nn.Linear(d_model,decoder_vocab)\n",
    "        \n",
    "    def forward(self, src_seq, src_mask, trg_seq):\n",
    "        trg_mask = get_pad_mask(trg_seq, self.trg_pad_idx) & get_subsequent_mask(trg_seq)\n",
    "\n",
    "        enc_output = self.encoder(input_ids = src_seq, attention_mask = src_mask)\n",
    "        dec_output, *_ = self.decoder(trg_seq, trg_mask, enc_output[0], src_mask)\n",
    "        seq_logit = self.trg_word_prj(dec_output)\n",
    "        \n",
    "        return seq_logit.view(-1, seq_logit.size(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8e482fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_performance(pred, gold, trg_pad_idx):\n",
    "\n",
    "    pred = pred.max(1)[1]\n",
    "    gold = gold.contiguous().view(-1)\n",
    "    non_pad_mask = gold.ne(trg_pad_idx)\n",
    "    n_correct = pred.eq(gold).masked_select(non_pad_mask).sum().item()\n",
    "    n_word = non_pad_mask.sum().item()\n",
    "\n",
    "    return  n_correct, n_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2430a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_encoder = roberta_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "502c508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Modified_Transformer(pretrained_encoder\n",
    "                        ,pretrained_encoder.embeddings.word_embeddings.weight.shape[0]\n",
    "                        ,pretrained_encoder.embeddings.word_embeddings.weight.shape[1]\n",
    "                        ,n_layers = 2\n",
    "                        ,attn_heads = 2\n",
    "                        ,d_ffn = 2048\n",
    "                        ,pad_idx = 1\n",
    "                        ,n_positions = 512)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.98), eps=1e-09)\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=1, reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "d9212d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_text = dataset['outline_1'][:95]\n",
    "target_text = dataset['original_text'][:95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "089743f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Modified_Transformer(\n",
       "  (encoder): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (trg_word_emb): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_enc): PositionalEncoding()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (layer_stack): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (slf_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (w_ks): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (w_vs): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (fc): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (enc_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (w_ks): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (w_vs): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (fc): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (slf_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (w_ks): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (w_vs): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (fc): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (enc_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (w_ks): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (w_vs): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (fc): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (trg_word_prj): Linear(in_features=768, out_features=50265, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "25c251e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 20 Accuracy: 16.903394435464456 Loss: 5.127254665162354\n",
      "Iteration: 40 Accuracy: 20.187777281012483 Loss: 4.480524094531062\n",
      "Iteration: 60 Accuracy: 28.689342091687585 Loss: 3.86455051550557\n",
      "Iteration: 80 Accuracy: 36.62344808611617 Loss: 3.458754454640709\n",
      "Iteration: 100 Accuracy: 46.125803899989684 Loss: 2.9779215256195433\n",
      "Iteration: 120 Accuracy: 53.210441242218934 Loss: 2.6554708760603916\n",
      "Iteration: 140 Accuracy: 59.98555559376827 Loss: 2.3695889527504894\n",
      "Iteration: 160 Accuracy: 65.00326718712385 Loss: 2.181097382302338\n",
      "Iteration: 180 Accuracy: 70.47838497781753 Loss: 1.9595667609495437\n",
      "Iteration: 200 Accuracy: 75.15906042576607 Loss: 1.8394404969968277\n",
      "Iteration: 220 Accuracy: 78.12704199195241 Loss: 1.6899248793499297\n",
      "Iteration: 240 Accuracy: 81.82068301406609 Loss: 1.590391985245189\n"
     ]
    }
   ],
   "source": [
    "iteration = 240\n",
    "batch_size = 16\n",
    "for e in range(iteration):\n",
    "    train_loss = 0\n",
    "    train_total_correct, train_total_number_of_words = 0, 0\n",
    "    optimizer.zero_grad()\n",
    "    for i,_ in enumerate(source_text):\n",
    "        if source_text[i] == \"\" or target_text[i] == \"\":\n",
    "            break\n",
    "        source = roberta_tokenizer(source_text[i],return_tensors='pt',truncation=True).to('cuda')\n",
    "        target = roberta_tokenizer(target_text[i],return_tensors='pt',truncation=True).to('cuda')\n",
    "        golden = target['input_ids'][:,1:]\n",
    "        decoder_target = target['input_ids'][:,:-1]\n",
    "        output = model(source['input_ids'],source['attention_mask'],decoder_target)\n",
    "        loss_value = loss_function(output,golden.view(-1))\n",
    "        correct_words, number_of_words = cal_performance(output,golden,1)\n",
    "        train_total_correct += correct_words\n",
    "        train_total_number_of_words += number_of_words\n",
    "        train_loss += loss_value.item()\n",
    "        loss_value.backward()\n",
    "        if (i+1) % batch_size == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "    if (e+1) % 20 == 0:\n",
    "        step_accuracy = train_total_correct / train_total_number_of_words\n",
    "        step_loss = train_loss / train_total_number_of_words\n",
    "        print(f'Iteration: {e+1} Accuracy: {step_accuracy * 100} Loss: {step_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "0c826e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator(nn.Module):\n",
    "    def __init__(\n",
    "            self, model, beam_size, max_seq_len,\n",
    "            src_pad_idx, trg_pad_idx, trg_bos_idx, trg_eos_idx):\n",
    "        \n",
    "        super(Translator, self).__init__()\n",
    "\n",
    "        self.alpha = 0.7\n",
    "        self.beam_size = beam_size\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_bos_idx = trg_bos_idx\n",
    "        self.trg_eos_idx = trg_eos_idx\n",
    "\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "\n",
    "        self.register_buffer('init_seq', torch.LongTensor([[trg_bos_idx]]))\n",
    "        self.register_buffer(\n",
    "            'blank_seqs', \n",
    "            torch.full((beam_size, max_seq_len), trg_pad_idx, dtype=torch.long))\n",
    "        self.blank_seqs[:, 0] = self.trg_bos_idx\n",
    "        self.register_buffer(\n",
    "            'len_map', \n",
    "            torch.arange(1, max_seq_len + 1, dtype=torch.long).unsqueeze(0))\n",
    "\n",
    "\n",
    "    def _model_decode(self, trg_seq, enc_output, src_mask):\n",
    "        trg_mask = get_subsequent_mask(trg_seq)\n",
    "        dec_output, *_ = self.model.decoder(trg_seq, trg_mask, enc_output, src_mask)\n",
    "        return F.softmax(self.model.trg_word_prj(dec_output), dim=-1)\n",
    "\n",
    "\n",
    "    def _get_init_state(self, src_seq, src_mask):\n",
    "        beam_size = self.beam_size\n",
    "        enc_output = self.model.encoder(input_ids = src_seq, attention_mask = src_mask)\n",
    "        enc_output = enc_output[0]\n",
    "        dec_output = self._model_decode(self.init_seq, enc_output, src_mask)\n",
    "        best_k_probs, best_k_idx = dec_output[:, -1, :].topk(beam_size)\n",
    "\n",
    "        scores = torch.log(best_k_probs).view(beam_size)\n",
    "        gen_seq = self.blank_seqs.clone().detach()\n",
    "        gen_seq[:, 1] = best_k_idx[0]\n",
    "        enc_output = enc_output.repeat(beam_size, 1, 1)\n",
    "        return enc_output, gen_seq, scores\n",
    "\n",
    "\n",
    "    def _get_the_best_score_and_idx(self, gen_seq, dec_output, scores, step):\n",
    "        assert len(scores.size()) == 1\n",
    "        \n",
    "        beam_size = self.beam_size\n",
    "\n",
    "        # Get k candidates for each beam, k^2 candidates in total.\n",
    "        best_k2_probs, best_k2_idx = dec_output[:, -1, :].topk(beam_size)\n",
    "\n",
    "        # Include the previous scores.\n",
    "        scores = torch.log(best_k2_probs).view(beam_size, -1) + scores.view(beam_size, 1)\n",
    "\n",
    "        # Get the best k candidates from k^2 candidates.\n",
    "        scores, best_k_idx_in_k2 = scores.view(-1).topk(beam_size)\n",
    " \n",
    "        # Get the corresponding positions of the best k candidiates.\n",
    "        best_k_r_idxs, best_k_c_idxs = best_k_idx_in_k2 // beam_size, best_k_idx_in_k2 % beam_size\n",
    "        best_k_idx = best_k2_idx[best_k_r_idxs, best_k_c_idxs]\n",
    "\n",
    "        # Copy the corresponding previous tokens.\n",
    "        gen_seq[:, :step] = gen_seq[best_k_r_idxs, :step]\n",
    "        # Set the best tokens in this beam search step\n",
    "        gen_seq[:, step] = best_k_idx\n",
    "\n",
    "        return gen_seq, scores\n",
    "\n",
    "\n",
    "    def translate_sentence(self, src_seq,src_mask):\n",
    "        assert src_seq.size(0) == 1\n",
    "\n",
    "        src_pad_idx, trg_eos_idx = self.src_pad_idx, self.trg_eos_idx \n",
    "        max_seq_len, beam_size, alpha = self.max_seq_len, self.beam_size, self.alpha \n",
    "\n",
    "        with torch.no_grad():\n",
    "            enc_output, gen_seq, scores = self._get_init_state(src_seq, src_mask)\n",
    "\n",
    "            ans_idx = 0\n",
    "            for step in range(2, max_seq_len):    # decode up to max length\n",
    "                dec_output = self._model_decode(gen_seq[:, :step], enc_output, src_mask)\n",
    "                gen_seq, scores = self._get_the_best_score_and_idx(gen_seq, dec_output, scores, step)\n",
    "\n",
    "                # Check if all path finished\n",
    "                # -- locate the eos in the generated sequences\n",
    "                eos_locs = gen_seq == trg_eos_idx   \n",
    "                # -- replace the eos with its position for the length penalty use\n",
    "                seq_lens, _ = self.len_map.masked_fill(~eos_locs, max_seq_len).min(1)\n",
    "                # -- check if all beams contain eos\n",
    "                if (eos_locs.sum(1) > 0).sum(0).item() == beam_size:\n",
    "                    _, ans_idx = scores.div(seq_lens.float() ** alpha).max(0)\n",
    "                    ans_idx = ans_idx.item()\n",
    "                    break\n",
    "        return gen_seq[ans_idx][:seq_lens[ans_idx]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "b5c787c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator(model,5,512,1,1,0,2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "b77d01ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_source_text = dataset['outline_1'][95:].tolist()\n",
    "test_target_text = dataset['original_text'][95:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "6519a0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\anaconda3\\envs\\opennmttorch\\lib\\site-packages\\ipykernel_launcher.py:63: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n"
     ]
    }
   ],
   "source": [
    "source = roberta_tokenizer(test_source_text,return_tensors='pt').to('cuda')\n",
    "pred_seq = translator.translate_sentence(source['input_ids'],source['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "3c3b1fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent = roberta_tokenizer.decode(pred_seq,skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "be77872f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The approaches assume that the structure is known prior, or can be learned from accessible sources\\nThis leads to the question: can low-dimensional data from the data been learned subject to differential privacy?\\nTo answer this, we consider the scenario where the data is in Rd but also in, or very close to a linear sub-space of dimension k We then consider the case where k (cid:28) d an develop algorithms whose sample complexity is independent of the ambient dimension d, as a polynomial dependence on the true dimension k cannot be avoided\\nThe algorithms find the according subspace, or an approximation if the data is slightly altered\\nJust identifying the subspace structure is a noteworthy capability on its own, but it can be further used for pre-processing in further analysis\\nProjection to the low-dimensional subspace ensures that following data analysis steps do not deal with high-dimensional data\\n\\n1.1 Our Contributions: Privately Learning Subspaces â€“ Exact Case:\\nFirst we considered the exact case where the data X1, Â· Â· Â· , Xnâˆˆ Rd are assumed to lie in a k-dimensional subspace (rather than merely being near to it) â€“ i.e., rank (A) = k, where A = (cid:80)n'"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_source_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "73898f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Part ofat1\\x0cHowever, these approaches assume that this structure is known a priori or that it can be learned\\nfrom non-private sources. This raises the question:Can we learn low-dimensional structure from the data subject to differential privacy?We consider the simple setting where the data lies in Rd but is in, or very close to a linear sub-\\nspace, of dimension k. We focus on the setting where k (cid:28) d and we develop algorithms whose\\nsample complexity does not depend on the ambient dimension d; a polynomial dependence on\\nthe true dimension k is unavoidable.Our algorithms identify the subspace in question or, if the data is perturbed slightly, an\\napproximation to it. Identifying the subspace structure is interesting in its own right, but it also\\ncan be used as a pre-processing step for further analysis â€“ by projecting to the low-dimensional\\nsubspace, we ensure subsequent data analysis steps do not need to deal with high-dimensional\\ndata.1.1 Our Contributions: Privately Learning Subspaces â€“ Exact CaseWe ï¬rst consider the exact case, where the data X1, Â· Â· Â· , Xnâˆˆ Rd are assumed to lie in a\\nk-dimensional subspace (rather than merely being near to it) â€“ i.e., rank (A) = k, where A =\\n(cid:80)n'"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "62c6096d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Part ofat1\\x0cHowever, these approaches assume that this structure is known a priori or that it can be learned\\nfrom non-private sources. This raises the question:Can we learn low-dimensional structure from the data subject to differential privacy?We consider the simple setting where the data lies in Rd but is in, or very close to a linear sub-\\nspace, of dimension k. We focus on the setting where k (cid:28) d and we develop algorithms whose\\nsample complexity does not depend on the ambient dimension d; a polynomial dependence on\\nthe true dimension k is unavoidable.Our algorithms identify the subspace in question or, if the data is perturbed slightly, an\\napproximation to it. Identifying the subspace structure is interesting in its own right, but it also\\ncan be used as a pre-processing step for further analysis â€“ by projecting to the low-dimensional\\nsubspace, we ensure subsequent data analysis steps do not need to deal with high-dimensional\\ndata.1.1 Our Contributions: Privately Learning Subspaces â€“ Exact CaseWe ï¬rst consider the exact case, where the data X1, Â· Â· Â·, Xnâˆˆ Rd are assumed to lie in a\\nk-dimensional subspace (rather than merely being near to it) â€“ i.e., rank (A) = k, where A =\\n(cid:80)n'"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba51d1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
